
# video-generation-survey

## 2023


+ [VIDM: Video Implicit Diffusion Models](https://arxiv.org/abs/2212.00235) (AAAI 2023)   
  [![Star](https://img.shields.io/github/stars/MKFMIKU/VIDM.svg?style=social&label=Star)](https://github.com/MKFMIKU/VIDM) 
  [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2212.00235) 
  [![Website](https://img.shields.io/badge/Website-9cf)](https://kfmei.page/vidm/)

+ [Mm-Diffusion: Learning Multi-Modal Diffusion Models for Joint Audio and Video Generation](https://arxiv.org/abs/2212.09478) (CVPR 2023)   
  [![Star](https://img.shields.io/github/stars/researchmm/MM-Diffusion.svg?style=social&label=Star)](https://github.com/researchmm/MM-Diffusion) 
  [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2212.09478)

+ [Video Probabilistic Diffusion Models in Projected Latent Space](https://arxiv.org/abs/2302.07685) (CVPR 2023)   
  [![Star](https://img.shields.io/github/stars/sihyun-yu/PVDM.svg?style=social&label=Star)](https://github.com/sihyun-yu/PVDM) 
  [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2302.07685) 
  [![Website](https://img.shields.io/badge/Website-9cf)](https://sihyun.me/PVDM/)

+ [VideoFusion: Decomposed Diffusion Models for High-Quality Video Generation](https://arxiv.org/abs/2303.08320) (CVPR 2023)   
  [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2303.08320) 
  [![Website](https://img.shields.io/badge/Website-9cf)](https://modelscope.cn/models/damo/text-to-video-synthesis/summary)

+ [Conditional Image-to-Video Generation with Latent Flow Diffusion Models](https://arxiv.org/abs/2303.13744) (CVPR 2023)   
  [![Star](https://img.shields.io/github/stars/nihaomiao/CVPR23_LFDM.svg?style=social&label=Star)](https://github.com/nihaomiao/CVPR23_LFDM) 
  [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2303.13744)

+ [Physics-Driven Diffusion Models for Impact Sound Synthesis from Videos](https://arxiv.org/abs/2303.16897) (CVPR 2023)  
  [![Star](https://img.shields.io/github/stars/sukun1045/video-physics-sound-diffusion.svg?style=social&label=Star)](https://github.com/sukun1045/video-physics-sound-diffusion) 
  [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2303.16897) 
  [![Website](https://img.shields.io/badge/Website-9cf)](https://sukun1045.github.io/video-physics-sound-diffusion/)

+ [Align your Latents: High-Resolution Video Synthesis with Latent Diffusion Models](https://arxiv.org/abs/2304.08818) (CVPR 2023)  
  [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2304.08818) 
  [![Website](https://img.shields.io/badge/Website-9cf)](https://research.nvidia.com/labs/toronto-ai/VideoLDM/)

+ [3D Cinemagraphy from a Single Image](https://arxiv.org/abs/2303.05724) (CVPR 2023)  
  [![Star](https://img.shields.io/github/stars/xingyi-li/3d-cinemagraphy.svg?style=social&label=Star)](https://github.com/xingyi-li/3d-cinemagraphy)
  [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2303.05724) 
  [![Website](https://img.shields.io/badge/Website-9cf)](https://xingyi-li.github.io/3d-cinemagraphy/)

+ [MOSO: Decomposing MOtion, Scene and Object for Video Prediction](https://arxiv.org/abs/2303.03684) (CVPR 2023)  
  [![Star](https://img.shields.io/github/stars/iva-mzsun/MOSO.svg?style=social&label=Star)](https://github.com/iva-mzsun/MOSO)
  [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2303.03684) 
  [![Website](https://img.shields.io/badge/Website-9cf)](https://iva-mzsun.github.io/MOSO)

+ [SadTalker: Learning Realistic 3D Motion Coefficients for Stylized Audio-Driven Single Image Talking Face Animation](https://arxiv.org/abs/2211.12194) (CVPR 2023)  
  [![Star](https://img.shields.io/github/stars/OpenTalker/SadTalker.svg?style=social&label=Star)](https://github.com/OpenTalker/SadTalker)
  [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2211.12194)
  [![Website](https://img.shields.io/badge/Website-9cf)](https://sadtalker.github.io/)

+ [Towards End-to-End Generative Modeling of Long Videos with Memory-Efficient Bidirectional Transformers](https://arxiv.org/abs/2303.11251) (CVPR 2023)  
  [![Star](https://img.shields.io/github/stars/Ugness/MeBT.svg?style=social&label=Star)](https://github.com/Ugness/MeBT)
  [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2303.11251)
  [![Website](https://img.shields.io/badge/Website-9cf)](https://sites.google.com/view/mebt-cvpr2023)

+ [ Learning Universal Policies via Text-Guided Video Generation ]( https://arxiv.org/abs/2302.00111 )   
  [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)]( https://arxiv.org/abs/2302.00111 ) 
  [![Website](https://img.shields.io/badge/Website-9cf)]( https://universal-policy.github.io/unipi/ )

+ [ Tell me what happened: Unifying text-guided video completion via multimodal masked video generation ]( https://openaccess.thecvf.com/content/CVPR2023/papers/Fu_Tell_Me_What_Happened_Unifying_Text-Guided_Video_Completion_via_Multimodal_CVPR_2023_paper.pdf ) (CVPR 2023)   
  [![Star](https://img.shields.io/github/stars/tsujuifu/pytorch_tvc.svg?style=social&label=Star)]( https://github.com/tsujuifu/pytorch_tvc ) 
  [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)]( https://arxiv.org/abs/2211.12824 ) 
  [![Website](https://img.shields.io/badge/Website-9cf)]( https://tvc-mmvg.github.io/ )

+ [ Latent-shift: Latent diffusion with temporal shift for efficient text-to-video generation ]( https://arxiv.org/pdf/2304.08477.pdf )    
  [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)]( https://arxiv.org/abs/2304.08477 ) 
  [![Website](https://img.shields.io/badge/Website-9cf)]( https://latent-shift.github.io/ )

+ [ Video-p2p: Video editing with cross-attention control ]( https://arxiv.org/abs/2303.04761 )    
  [![Star](https://img.shields.io/github/stars/ShaoTengLiu/Video-P2P.svg?style=social&label=Star)]( https://github.com/ShaoTengLiu/Video-P2P ) 
  [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)]( https://arxiv.org/abs/2303.04761 ) 
  [![Website](https://img.shields.io/badge/Website-9cf)]( https://video-p2p.github.io/ )

+ [ MAGVIT: Masked Generative Video Transformer ]( https://openaccess.thecvf.com/content/CVPR2023/papers/Yu_MAGVIT_Masked_Generative_Video_Transformer_CVPR_2023_paper.pdf ) (CVPR 2023)   
  [![Star](https://img.shields.io/github/stars/google-research/magvit.svg?style=social&label=Star)]( https://github.com/google-research/magvit ) 
  [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)]( https://arxiv.org/abs/2212.05199 ) 
  [![Website](https://img.shields.io/badge/Website-9cf)]( https://magvit.cs.cmu.edu/ )

+ [ Text2video-zero: Text-to-image diffusion models are zero-shot video generators ]( https://arxiv.org/abs/2303.13439 )    
  [![Star](https://img.shields.io/github/stars/Picsart-AI-Research/Text2Video-Zero.svg?style=social&label=Star)]( https://github.com/Picsart-AI-Research/Text2Video-Zero ) 
  [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)]( https://arxiv.org/abs/2303.13439 ) 
  [![Website](https://img.shields.io/badge/Website-9cf)]( https://text2video-zero.github.io/ )


## 2022


+ [Video Diffusion Models](https://arxiv.org/abs/2204.03458) (NeurIPS 2022)   
  [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2204.03458) 
  [![Website](https://img.shields.io/badge/Website-9cf)](https://video-diffusion.github.io/)

+ [McVd: Masked Conditional Video Diffusion for Prediction, Generation, and Interpolation](https://arxiv.org/abs/2205.09853) (NeurIPS 2022)   
  [![Star](https://img.shields.io/github/stars/Tobi-r9/RaMViD.svg?style=social&label=Star)](https://github.com/voletiv/mcvd-pytorch)
  [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2205.09853) 
  [![Website](https://img.shields.io/badge/Website-9cf)](https://mask-cond-video-diffusion.github.io)

+ [Diffusion Models for Video Prediction and Infilling](https://arxiv.org/abs/2206.07696) (TMLR 2022)   
  [![Star](https://img.shields.io/github/stars/Tobi-r9/RaMViD.svg?style=social&label=Star)](https://github.com/Tobi-r9/RaMViD) 
  [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2206.07696) 
  [![Website](https://img.shields.io/badge/Website-9cf)](https://sites.google.com/view/video-diffusion-prediction)

+ [Make-A-Video: Text-to-Video Generation without Text-Video Data](https://openreview.net/forum?id=nJfylDvgzlq) (ICLR 2023)   
  [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://openreview.net/forum?id=nJfylDvgzlq) 
  [![Website](https://img.shields.io/badge/Website-9cf)](https://makeavideo.studio)

+ [Depth-Aware Generative Adversarial Network for Talking Head Video Generation](https://arxiv.org/abs/2203.06605) (CVPR 2022)   
  [![Star](https://img.shields.io/github/stars/harlanhong/CVPR2022-DaGAN.svg?style=social&label=Star)](https://github.com/harlanhong/CVPR2022-DaGAN) 
  [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2203.06605)

+ [Show Me What and Tell Me How: Video Synthesis via Multimodal Conditioning](https://arxiv.org/abs/2203.02573) (CVPR 2022)   
  [![Star](https://img.shields.io/github/stars/snap-research/MMVID.svg?style=social&label=Star)](https://github.com/snap-research/MMVID) 
  [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2203.02573) 
  [![Website](https://img.shields.io/badge/Website-9cf)](https://snap-research.github.io/MMVID/)

+ [Playable Environments: Video Manipulation in Space and Time](https://arxiv.org/abs/2203.01914) (CVPR 2022)   
  [![Star](https://img.shields.io/github/stars/willi-menapace/PlayableEnvironments.svg?style=social&label=Star)](https://github.com/willi-menapace/PlayableEnvironments) 
  [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2203.01914) 
  [![Website](https://img.shields.io/badge/Website-9cf)](https://willi-menapace.github.io/playable-environments-website/)

+ [Fast-Vid2Vid: Spatial-Temporal Compression for Video-to-Video Synthesis](https://arxiv.org/abs/2207.05049) (ECCV 2022)   
  [![Star](https://img.shields.io/github/stars/fast-vid2vid/fast-vid2vid.svg?style=social&label=Star)](https://github.com/fast-vid2vid/fast-vid2vid) 
  [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2207.05049) 
  [![Website](https://img.shields.io/badge/Website-9cf)](https://fast-vid2vid.github.io/)

+ [TM2T: Stochastic and Tokenized Modeling for the Reciprocal Generation of 3D Human Motions and Texts](https://arxiv.org/abs/2207.01696) (ECCV 2022)   
  [![Star](https://img.shields.io/github/stars/EricGuo5513/TM2T.svg?style=social&label=Star)](https://github.com/EricGuo5513/TM2T) 
  [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2207.01696) 
  [![Website](https://img.shields.io/badge/Website-9cf)](https://ericguo5513.github.io/TM2T/)

## 2021
+ [Click to Move: Controlling Video Generation with Sparse Motion](https://arxiv.org/abs/2108.08815) (ICCV 2021)   
  [![Star](https://img.shields.io/github/stars/PierfrancescoArdino/C2M.svg?style=social&label=Star)](https://github.com/PierfrancescoArdino/C2M) 
  [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2108.08815) 


+ [VideoGPT: Video Generation using VQ-VAE and Transformers](https://arxiv.org/pdf/2104.10157v2.pdf)   
  [![Star](https://img.shields.io/github/stars/wilson1yan/VideoGPT.svg?style=social&label=Star)](https://github.com/wilson1yan/VideoGPT) 
  [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/pdf/2104.10157v2.pdf)
  [![Website](https://img.shields.io/badge/Website-9cf)](https://wilson1yan.github.io/videogpt/index.html)


+ [Latent Neural Differential Equations for Video Generation](https://arxiv.org/pdf/2011.03864v3.pdf)   
  [![Star](https://img.shields.io/github/stars/Zasder3/Latent-Neural-Differential-Equations-for-Video-Generation.svg?style=social&label=Star)](https://github.com/Zasder3/Latent-Neural-Differential-Equations-for-Video-Generation) 
  [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/pdf/2011.03864v3.pdf)

+ [ Stochastic Image-to-Video Synthesis Using cINNs ]( https://openaccess.thecvf.com/content/CVPR2021/papers/Dorkenwald_Stochastic_Image-to-Video_Synthesis_Using_cINNs_CVPR_2021_paper.pdf ) (CVPR 2021)   
  [![Star](https://img.shields.io/github/stars/CompVis/image2video-synthesis-using-cINNs.svg?style=social&label=Star)]( https://github.com/CompVis/image2video-synthesis-using-cINNs ) 
  [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)]( https://arxiv.org/abs/2105.04551 ) 
  [![Website](https://img.shields.io/badge/Website-9cf)]( https://compvis.github.io/image2video-synthesis-using-cINNs/ )


+ [ Understanding Object Dynamics for Interactive Image-to-Video Synthesis ]( https://openaccess.thecvf.com/content/CVPR2021/papers/Blattmann_Understanding_Object_Dynamics_for_Interactive_Image-to-Video_Synthesis_CVPR_2021_paper.pdf ) (CVPR 2021)   
  [![Star](https://img.shields.io/github/stars/CompVis/interactive-image2video-synthesis.svg?style=social&label=Star)]( https://github.com/CompVis/interactive-image2video-synthesis ) 
  [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)]( https://arxiv.org/abs/2106.11303 ) 
  [![Website](https://img.shields.io/badge/Website-9cf)]( https://compvis.github.io/interactive-image2video-synthesis/ )

+ [ One-Shot Free-View Neural Talking-Head Synthesis for Video Conferencing ]( https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_One-Shot_Free-View_Neural_Talking-Head_Synthesis_for_Video_Conferencing_CVPR_2021_paper.pdf ) (CVPR 2021)   
  [![Star](https://img.shields.io/github/stars/zhanglonghao1992/One-Shot_Free-View_Neural_Talking_Head_Synthesis.svg?style=social&label=Star)]( https://github.com/zhanglonghao1992/One-Shot_Free-View_Neural_Talking_Head_Synthesis ) 
  [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)]( https://arxiv.org/abs/2011.15126 ) 

+ [ Flow Guided Transformable Bottleneck Networks for Motion Retargeting ]( https://openaccess.thecvf.com/content/CVPR2021/papers/Ren_Flow_Guided_Transformable_Bottleneck_Networks_for_Motion_Retargeting_CVPR_2021_paper.pdf ) (CVPR 2021)   
  [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)]( https://arxiv.org/abs/2106.07771 ) 

+ [ Stable View Synthesis ]( https://openaccess.thecvf.com/content/CVPR2021/papers/Riegler_Stable_View_Synthesis_CVPR_2021_paper.pdf ) (CVPR 2021)   
  [![Star](https://img.shields.io/github/stars/isl-org/StableViewSynthesis.svg?style=social&label=Star)]( https://github.com/isl-org/StableViewSynthesis ) 
  [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)]( https://arxiv.org/abs/2011.07233 ) 

+ [ Scene-Aware Generative Network for Human Motion Synthesis ]( https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_Scene-Aware_Generative_Network_for_Human_Motion_Synthesis_CVPR_2021_paper.pdf ) (CVPR 2021)   
  [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)]( https://arxiv.org/abs/2105.14804 ) 
  
+ [ Neural Scene Flow Fields for Space-Time View Synthesis of Dynamic Scenes ]( https://openaccess.thecvf.com/content/CVPR2021/papers/Li_Neural_Scene_Flow_Fields_for_Space-Time_View_Synthesis_of_Dynamic_CVPR_2021_paper.pdf ) (CVPR 2021)   
  [![Star](https://img.shields.io/github/stars/zhengqili/Neural-Scene-Flow-Fields.svg?style=social&label=Star)]( https://github.com/zhengqili/Neural-Scene-Flow-Fields ) 
  [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)]( https://arxiv.org/abs/2011.13084 ) 
  
+ [ Deep Animation Video Interpolation in the Wild ]( https://openaccess.thecvf.com/content/CVPR2021/papers/Siyao_Deep_Animation_Video_Interpolation_in_the_Wild_CVPR_2021_paper.pdf ) (CVPR 2021)   
  [![Star](https://img.shields.io/github/stars/lisiyao21/AnimeInterp.svg?style=social&label=Star)]( https://github.com/lisiyao21/AnimeInterp ) 
  [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)]( https://arxiv.org/abs/2104.02495 ) 

+ [ High-Fidelity Neural Human Motion Transfer from Monocular Video ]( https://openaccess.thecvf.com/content/CVPR2021/papers/Kappel_High-Fidelity_Neural_Human_Motion_Transfer_From_Monocular_Video_CVPR_2021_paper.pdf ) (CVPR 2021)   
  [![Star](https://img.shields.io/github/stars/MoritzKappel/HF-NHMT.svg?style=social&label=Star)]( https://github.com/MoritzKappel/HF-NHMT ) 
  [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)]( https://arxiv.org/abs/2012.10974 ) 

+ [ Learning Semantic-Aware Dynamics for Video Prediction ]( https://openaccess.thecvf.com/content/CVPR2021/papers/Bei_Learning_Semantic-Aware_Dynamics_for_Video_Prediction_CVPR_2021_paper.pdf ) (CVPR 2021)   
  [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)]( https://arxiv.org/abs/2104.09762 ) 

+ [ Flow-Guided One-Shot Talking Face Generation With a High-Resolution Audio-Visual Dataset ]( https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_Flow-Guided_One-Shot_Talking_Face_Generation_With_a_High-Resolution_Audio-Visual_Dataset_CVPR_2021_paper.pdf ) (CVPR 2021)   
  [![Star](https://img.shields.io/github/stars/MRzzm/HDTF.svg?style=social&label=Star)]( https://github.com/MRzzm/HDTF ) 

+ [ Layout-Guided Novel View Synthesis From a Single Indoor Panorama ]( https://openaccess.thecvf.com/content/CVPR2021/papers/Xu_Layout-Guided_Novel_View_Synthesis_From_a_Single_Indoor_Panorama_CVPR_2021_paper.pdf ) (CVPR 2021)   
  [![Star](https://img.shields.io/github/stars/bluestyle97/PNVS.svg?style=social&label=Star)]( https://github.com/bluestyle97/PNVS ) 
  [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)]( https://arxiv.org/abs/2103.17022 ) 

+ [ Space-Time Neural Irradiance Fields for Free-Viewpoint Video ]( https://openaccess.thecvf.com/content/CVPR2021/papers/Xian_Space-Time_Neural_Irradiance_Fields_for_Free-Viewpoint_Video_CVPR_2021_paper.pdf ) (CVPR 2021)   
  [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)]( https://arxiv.org/abs/2011.12950 ) 

+ [ GeoSim: Realistic Video Simulation via Geometry-Aware Composition for Self-Driving ]( https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_GeoSim_Realistic_Video_Simulation_via_Geometry-Aware_Composition_for_Self-Driving_CVPR_2021_paper.pdf ) (CVPR 2021)   
  [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)]( https://arxiv.org/abs/2101.06543 ) 
  [![Website](https://img.shields.io/badge/Website-9cf)]( https://tmux.top/publication/geosim/ )

+ [ Animating Pictures With Eulerian Motion Fields ]( https://openaccess.thecvf.com/content/CVPR2021/papers/Holynski_Animating_Pictures_With_Eulerian_Motion_Fields_CVPR_2021_paper.pdf ) (CVPR 2021)   
  [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)]( https://arxiv.org/abs/2011.15128 ) 
  [![Website](https://img.shields.io/badge/Website-9cf)]( https://eulerian.cs.washington.edu/ )


<!--
  // Entry template
  
+ [ TITLE ]( LINK ) (CONFERENCE)   
  [![Star](https://img.shields.io/github/stars/XXX/YYY.svg?style=social&label=Star)]( GITHUB ) 
  [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)]( ARXIV ) 
  [![Website](https://img.shields.io/badge/Website-9cf)]( WEBSITE )
  
-->
