{ '2016': [ { 'arxiv': 'https://arxiv.org/pdf/1611.10314',
              'conf': None,
              'github': 'https://github.com/Singularity42/Sync-DRAW',
              'title': 'Sync-DRAW: Automatic Video Generation using Deep '
                       'Recurrent Attentive Architectures',
              'website': None},
            { 'arxiv': 'https://arxiv.org/pdf/1605.07157',
              'conf': None,
              'github': 'https://github.com/Xiaohui9607/physical_interaction_video_prediction_pytorch',
              'title': 'Unsupervised Learning for Physical Interaction through '
                       'Video Prediction',
              'website': None}],
  '2017': [ { 'arxiv': 'https://arxiv.org/pdf/1711.11453',
              'conf': None,
              'github': 'https://github.com/bernhard2202/improved-video-gan',
              'title': 'Improving Video Generation for Multi-functional '
                       'Applications',
              'website': None},
            { 'arxiv': 'https://arxiv.org/pdf/1708.05980',
              'conf': 'ICCV 2017',
              'github': 'https://github.com/Singularity42/cap2vid',
              'title': 'Attentive Semantic Video Generation using Captions',
              'website': None},
            { 'arxiv': 'https://arxiv.org/pdf/1611.06624',
              'conf': 'ICCV 2017',
              'github': 'https://github.com/universome/stylegan-v',
              'title': 'Temporal Generative Adversarial Nets with Singular '
                       'Value Clipping',
              'website': 'https://pfnet-research.github.io/tgan/'}],
  '2018': [ { 'arxiv': 'https://arxiv.org/pdf/1812.01037',
              'conf': None,
              'github': 'https://github.com/sunxm2357/TwoStreamVAN',
              'title': 'TwoStreamVAN: Improving Motion Modeling in Video '
                       'Generation',
              'website': None},
            { 'arxiv': 'https://arxiv.org/pdf/1811.09393',
              'conf': None,
              'github': 'https://github.com/thunil/TecoGAN',
              'title': 'Learning Temporal Coherence via Self-Supervision for '
                       'GAN-based Video Generation',
              'website': 'https://ge.in.tum.de/wp-content/uploads/2020/05/ClickMe.html'},
            { 'arxiv': 'https://arxiv.org/pdf/1810.02419',
              'conf': None,
              'github': 'https://github.com/musikisomorphie/swd',
              'title': 'Towards High Resolution Video Generation with '
                       'Progressive Growing of Sliced Wasserstein GANs',
              'website': None},
            { 'arxiv': 'https://arxiv.org/pdf/1808.07371',
              'conf': 'ICCV 2019',
              'github': 'https://github.com/carolineec/EverybodyDanceNow',
              'title': 'Everybody Dance Now',
              'website': None},
            { 'arxiv': 'https://arxiv.org/pdf/1807.09951',
              'conf': 'ECCV 2018',
              'github': 'https://github.com/garyzhao/FRGAN',
              'title': 'Learning to Forecast and Refine Residual Motion for '
                       'Image-to-Video Generation',
              'website': 'https://garyzhao.github.io/archives/eccv18_frgan_poster.pdf'},
            { 'arxiv': 'https://arxiv.org/pdf/1804.04786',
              'conf': None,
              'github': 'https://github.com/susanqq/Talking_Face_Generation',
              'title': 'Talking Face Generation by Conditional Recurrent '
                       'Adversarial Network',
              'website': None},
            { 'arxiv': 'https://arxiv.org/pdf/1803.08085',
              'conf': 'ECCV 2018',
              'github': 'https://github.com/yccyenchicheng/pytorch-VideoVAE',
              'title': 'Probabilistic Video Generation using Holistic '
                       'Attribute Control',
              'website': None},
            { 'arxiv': 'https://arxiv.org/pdf/1802.07687',
              'conf': 'ICML 2018',
              'github': 'https://github.com/edenton/svg',
              'title': 'Stochastic Video Generation with a Learned Prior',
              'website': 'https://holmdk.github.io/2020/01/22/stochastic_vid.html'},
            { 'arxiv': 'https://arxiv.org/pdf/1802.07687',
              'conf': 'ICML 2018',
              'github': 'https://github.com/edenton/svg',
              'title': 'Stochastic Video Generation with a Learned Prior',
              'website': 'https://holmdk.github.io/2020/01/22/stochastic_vid.html'},
            { 'arxiv': 'https://arxiv.org/pdf/1710.11252',
              'conf': 'ICLR 2018',
              'github': 'https://github.com/RoboTurk-Platform/roboturk_real_dataset',
              'title': 'Stochastic Variational Video Prediction',
              'website': None},
            { 'arxiv': 'https://arxiv.org/pdf/1711.09618',
              'conf': 'AAAI 2018',
              'github': 'https://github.com/mil-tokyo/FTGAN',
              'title': 'Hierarchical Video Generation from Orthogonal '
                       'Information: Optical Flow and Texture',
              'website': None},
            { 'arxiv': 'https://arxiv.org/pdf/1707.04993',
              'conf': 'CVPR 2018',
              'github': 'https://github.com/sergeytulyakov/mocogan',
              'title': 'MoCoGAN: Decomposing Motion and Content for Video '
                       'Generation',
              'website': None}],
  '2019': [ { 'arxiv': 'https://arxiv.org/pdf/2002.09219',
              'conf': None,
              'github': 'https://github.com/xrenaa/Music-Dance-Video-Synthesis',
              'title': 'Music-oriented Dance Video Synthesis with Pose '
                       'Perceptual Loss',
              'website': None},
            { 'arxiv': 'https://arxiv.org/pdf/1910.09139',
              'conf': None,
              'github': 'https://github.com/ubc-vision/DwNet',
              'title': 'DwNet: Dense warp-based network for pose-guided human '
                       'video generation',
              'website': None},
            { 'arxiv': 'https://arxiv.org/pdf/1907.08845',
              'conf': None,
              'github': 'https://github.com/andrewjywang/SEENet',
              'title': 'Order Matters: Shuffling Sequence Generation for Video '
                       'Prediction',
              'website': None},
            { 'arxiv': 'https://arxiv.org/pdf/1907.06571',
              'conf': None,
              'github': 'https://github.com/Harrypotterrrr/DVD-GAN',
              'title': 'Adversarial Video Generation on Complex Datasets',
              'website': None},
            { 'arxiv': 'https://arxiv.org/pdf/1905.10240',
              'conf': None,
              'github': 'https://github.com/xih108/Video_Completion',
              'title': 'From Here to There: Video Inbetweening Using Direct 3D '
                       'Convolutions',
              'website': None},
            { 'arxiv': 'https://arxiv.org/pdf/1904.12165',
              'conf': 'ICCV 2019',
              'github': 'https://github.com/facebookresearch/improved_vrnn',
              'title': 'Improved Conditional VRNNs for Video Prediction',
              'website': None},
            { 'arxiv': 'https://arxiv.org/pdf/1706.02631',
              'conf': 'CVPR 2019',
              'github': 'https://github.com/musikisomorphie/swd',
              'title': 'Sliced Wasserstein Generative Models',
              'website': None},
            { 'arxiv': 'https://arxiv.org/pdf/1904.02912',
              'conf': 'ICCV 2019',
              'github': 'https://github.com/yccyenchicheng/p2pvg',
              'title': 'Point-to-Point Video Generation',
              'website': 'https://zswang666.github.io/P2PVG-Project-Page/'},
            { 'arxiv': 'https://arxiv.org/pdf/1903.06531',
              'conf': None,
              'github': 'https://github.com/panpanfei/Bringing-a-Blurry-Frame-Alive-at-High-Frame-Rate-with-an-Event-Camera',
              'title': 'High Frame Rate Video Reconstruction based on an Event '
                       'Camera',
              'website': None},
            { 'arxiv': 'https://arxiv.org/pdf/1903.04480',
              'conf': 'CVPR 2019',
              'github': 'https://github.com/junting/seg2vid',
              'title': 'Video Generation from Single Semantic Label Map',
              'website': None},
            { 'arxiv': 'https://arxiv.org/pdf/1901.11384',
              'conf': None,
              'github': 'https://github.com/belaalb/frameGAN',
              'title': 'Learning to navigate image manifolds induced by '
                       'generative adversarial networks for unsupervised video '
                       'generation',
              'website': None},
            { 'arxiv': 'https://arxiv.org/pdf/1812.08861',
              'conf': 'CVPR 2019',
              'github': 'https://github.com/AliaksandrSiarohin/monkey-net',
              'title': 'Animating Arbitrary Objects via Deep Motion Transfer',
              'website': None},
            { 'arxiv': 'https://arxiv.org/pdf/1812.02784',
              'conf': 'CVPR 2019',
              'github': 'https://github.com/yitong91/StoryGAN',
              'title': 'StoryGAN: A Sequential Conditional GAN for Story '
                       'Visualization',
              'website': None},
            { 'arxiv': 'https://arxiv.org/pdf/1804.01523',
              'conf': 'ICLR 2019',
              'github': 'https://github.com/alexlee-gk/video_prediction',
              'title': 'Stochastic Adversarial Video Prediction',
              'website': 'https://video-prediction.github.io/video_prediction/'}],
  '2020': [ { 'arxiv': 'https://arxiv.org/pdf/2011.10727',
              'conf': None,
              'github': 'https://github.com/ry85/Stochastic-Talking-Face-Generation-Using-Latent-Distribution-Matching',
              'title': 'Stochastic Talking Face Generation Using Latent '
                       'Distribution Matching',
              'website': None},
            { 'arxiv': 'https://arxiv.org/pdf/2011.03864',
              'conf': None,
              'github': 'https://github.com/Zasder3/Latent-Neural-Differential-Equations-for-Video-Generation',
              'title': 'Latent Neural Differential Equations for Video '
                       'Generation',
              'website': None},
            { 'arxiv': 'https://arxiv.org/pdf/2010.16078',
              'conf': None,
              'github': 'https://github.com/midas-research/linguistically-informed-frame-interpolation',
              'title': 'LIFI: Towards Linguistically Informed Frame '
                       'Interpolation',
              'website': None},
            { 'arxiv': 'https://arxiv.org/pdf/2007.06705',
              'conf': 'NeurIPS 2020',
              'github': 'https://github.com/pmh47/o3v',
              'title': 'Unsupervised object-centric video generation and '
                       'decomposition in 3D',
              'website': None},
            { 'arxiv': 'https://arxiv.org/pdf/2007.02808',
              'conf': 'ACCV 2020',
              'github': 'https://github.com/mlakhal/gtnet',
              'title': 'Novel-View Human Action Synthesis',
              'website': 'https://mlakhal.github.io/novel-view_action_synthesis.html'},
            { 'arxiv': 'https://arxiv.org/pdf/2007.01971',
              'conf': 'ECCV 2020',
              'github': 'https://github.com/PingYu-iris/SA-GCN',
              'title': 'Structure-Aware Human-Action Generation',
              'website': None},
            { 'arxiv': 'https://arxiv.org/pdf/2006.12226',
              'conf': 'NeurIPS 2020',
              'github': 'https://github.com/shirgur/hp-vae-gan',
              'title': 'Hierarchical Patch VAE-GAN: Generating Diverse Videos '
                       'from a Single Sample',
              'website': None},
            { 'arxiv': 'https://arxiv.org/pdf/2006.10704',
              'conf': None,
              'github': 'https://github.com/rakhimovv/lvt',
              'title': 'Latent Video Transformer',
              'website': None},
            { 'arxiv': 'https://arxiv.org/pdf/2002.10137',
              'conf': None,
              'github': 'https://github.com/yiranran/Audio-driven-TalkingFace-HeadPose',
              'title': 'Audio-driven Talking Face Video Generation with '
                       'Learning-based Personalized Head Pose',
              'website': None},
            { 'arxiv': 'https://arxiv.org/pdf/2002.09905',
              'conf': 'CVPR 2020',
              'github': 'https://github.com/Bei-Jin/STMFANet',
              'title': 'Exploring Spatial-Temporal Multi-Frequency Analysis '
                       'for High-Fidelity and Temporal-Consistency Video '
                       'Prediction',
              'website': None},
            { 'arxiv': 'https://arxiv.org/pdf/2002.09219',
              'conf': 'ICML 2020',
              'github': 'https://github.com/edouardelasalles/srvp',
              'title': 'Stochastic Latent Residual Video Prediction',
              'website': None},
            { 'arxiv': 'https://arxiv.org/pdf/1912.05523',
              'conf': 'CVPR 2020',
              'github': 'https://github.com/wyhsirius/g3an-project',
              'title': 'G3AN: Disentangling Appearance and Motion for Video '
                       'Generation',
              'website': 'https://wyhsirius.github.io/G3AN/'},
            { 'arxiv': 'https://arxiv.org/pdf/1906.02634',
              'conf': 'ICLR 2020',
              'github': 'https://github.com/rakhimovv/lvt',
              'title': 'Scaling Autoregressive Video Models',
              'website': None},
            { 'arxiv': 'https://arxiv.org/pdf/1903.04480',
              'conf': 'ICLR 2020',
              'github': 'https://github.com/tensorflow/tensor2tensor',
              'title': 'VideoFlow: A Conditional Flow-Based Model for '
                       'Stochastic Video Generation',
              'website': 'https://lucassheng.github.io/publication/pan-video-2019/'}],
  '2021': [ { 'arxiv': 'https://arxiv.org/pdf/2111.12417',
              'conf': None,
              'github': 'https://github.com/lucidrains/nuwa-pytorch',
              'title': 'NÜWA: Visual Synthesis Pre-training for Neural visUal '
                       'World creAtion',
              'website': 'https://www.microsoft.com/en-us/research/project/nuwa-infinity/'},
            { 'arxiv': 'https://arxiv.org/pdf/2110.11191',
              'conf': 'WACV 2022',
              'github': 'https://github.com/degardinbruno/kinetic-gan',
              'title': 'Generative Adversarial Graph Convolutional Networks '
                       'for Human Action Synthesis',
              'website': None},
            { 'arxiv': 'https://arxiv.org/pdf/2110.11894',
              'conf': None,
              'github': 'https://github.com/xsimba123/demos-of-csf-sa',
              'title': 'Towards Using Clothes Style Transfer for '
                       'Scenario-aware Person Video Generation',
              'website': None},
            { 'arxiv': 'https://arxiv.org/pdf/2203.09043',
              'conf': 'ICLR 2022',
              'github': 'https://github.com/wyhsirius/LIA',
              'title': 'Latent Image Animator: Learning to animate image via '
                       'latent space navigation',
              'website': 'https://wyhsirius.github.io/LIA-project/'},
            { 'arxiv': 'https://arxiv.org/pdf/2108.02760',
              'conf': 'ICCV 2021',
              'github': 'https://github.com/kaanakan/slamp',
              'title': 'SLAMP: Stochastic Latent Appearance and Motion '
                       'Prediction',
              'website': 'https://kuis-ai.github.io/slamp/'},
            { 'arxiv': 'https://arxiv.org/pdf/2108.04350',
              'conf': 'ICME 2021',
              'github': 'https://github.com/ChenDelong1999/VirtualConductor',
              'title': 'VirtualConductor: Music-driven Conducting Video '
                       'Generation System',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2108.08815',
              'conf': 'ICCV 2021',
              'github': 'https://github.com/PierfrancescoArdino/C2M',
              'title': 'Click to Move: Controlling Video Generation with '
                       'Sparse Motion',
              'website': None},
            { 'arxiv': 'https://arxiv.org/pdf/2104.10157v2.pdf',
              'conf': None,
              'github': 'https://github.com/wilson1yan/VideoGPT',
              'title': 'VideoGPT: Video Generation using VQ-VAE and '
                       'Transformers',
              'website': 'https://wilson1yan.github.io/videogpt/index.html'},
            { 'arxiv': 'https://arxiv.org/pdf/2011.03864v3.pdf',
              'conf': None,
              'github': 'https://github.com/Zasder3/Latent-Neural-Differential-Equations-for-Video-Generation',
              'title': 'Latent Neural Differential Equations for Video '
                       'Generation',
              'website': None},
            { 'arxiv': 'https://openaccess.thecvf.com/content/CVPR2021/papers/Dorkenwald_Stochastic_Image-to-Video_Synthesis_Using_cINNs_CVPR_2021_paper.pdf',
              'conf': 'CVPR 2021',
              'github': 'https://github.com/CompVis/image2video-synthesis-using-cINNs',
              'title': 'Stochastic Image-to-Video Synthesis Using cINNs',
              'website': 'https://compvis.github.io/image2video-synthesis-using-cINNs/'},
            { 'arxiv': 'https://openaccess.thecvf.com/content/CVPR2021/papers/Blattmann_Understanding_Object_Dynamics_for_Interactive_Image-to-Video_Synthesis_CVPR_2021_paper.pdf',
              'conf': 'CVPR 2021',
              'github': 'https://github.com/CompVis/interactive-image2video-synthesis',
              'title': 'Understanding Object Dynamics for Interactive '
                       'Image-to-Video Synthesis',
              'website': 'https://compvis.github.io/interactive-image2video-synthesis/'},
            { 'arxiv': 'https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_One-Shot_Free-View_Neural_Talking-Head_Synthesis_for_Video_Conferencing_CVPR_2021_paper.pdf',
              'conf': 'CVPR 2021',
              'github': 'https://github.com/zhanglonghao1992/One-Shot_Free-View_Neural_Talking_Head_Synthesis',
              'title': 'One-Shot Free-View Neural Talking-Head Synthesis for '
                       'Video Conferencing',
              'website': None},
            { 'arxiv': 'https://openaccess.thecvf.com/content/CVPR2021/papers/Ren_Flow_Guided_Transformable_Bottleneck_Networks_for_Motion_Retargeting_CVPR_2021_paper.pdf',
              'conf': 'CVPR 2021',
              'github': None,
              'title': 'Flow Guided Transformable Bottleneck Networks for '
                       'Motion Retargeting',
              'website': None},
            { 'arxiv': 'https://openaccess.thecvf.com/content/CVPR2021/papers/Riegler_Stable_View_Synthesis_CVPR_2021_paper.pdf',
              'conf': 'CVPR 2021',
              'github': 'https://github.com/isl-org/StableViewSynthesis',
              'title': 'Stable View Synthesis',
              'website': None},
            { 'arxiv': 'https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_Scene-Aware_Generative_Network_for_Human_Motion_Synthesis_CVPR_2021_paper.pdf',
              'conf': 'CVPR 2021',
              'github': None,
              'title': 'Scene-Aware Generative Network for Human Motion '
                       'Synthesis',
              'website': None},
            { 'arxiv': 'https://openaccess.thecvf.com/content/CVPR2021/papers/Li_Neural_Scene_Flow_Fields_for_Space-Time_View_Synthesis_of_Dynamic_CVPR_2021_paper.pdf',
              'conf': 'CVPR 2021',
              'github': 'https://github.com/zhengqili/Neural-Scene-Flow-Fields',
              'title': 'Neural Scene Flow Fields for Space-Time View Synthesis '
                       'of Dynamic Scenes',
              'website': None},
            { 'arxiv': 'https://openaccess.thecvf.com/content/CVPR2021/papers/Siyao_Deep_Animation_Video_Interpolation_in_the_Wild_CVPR_2021_paper.pdf',
              'conf': 'CVPR 2021',
              'github': 'https://github.com/lisiyao21/AnimeInterp',
              'title': 'Deep Animation Video Interpolation in the Wild',
              'website': None},
            { 'arxiv': 'https://openaccess.thecvf.com/content/CVPR2021/papers/Kappel_High-Fidelity_Neural_Human_Motion_Transfer_From_Monocular_Video_CVPR_2021_paper.pdf',
              'conf': 'CVPR 2021',
              'github': 'https://github.com/MoritzKappel/HF-NHMT',
              'title': 'High-Fidelity Neural Human Motion Transfer from '
                       'Monocular Video',
              'website': None},
            { 'arxiv': 'https://openaccess.thecvf.com/content/CVPR2021/papers/Bei_Learning_Semantic-Aware_Dynamics_for_Video_Prediction_CVPR_2021_paper.pdf',
              'conf': 'CVPR 2021',
              'github': None,
              'title': 'Learning Semantic-Aware Dynamics for Video Prediction',
              'website': None},
            { 'arxiv': 'https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_Flow-Guided_One-Shot_Talking_Face_Generation_With_a_High-Resolution_Audio-Visual_Dataset_CVPR_2021_paper.pdf',
              'conf': 'CVPR 2021',
              'github': 'https://github.com/MRzzm/HDTF',
              'title': 'Flow-Guided One-Shot Talking Face Generation With a '
                       'High-Resolution Audio-Visual Dataset',
              'website': None},
            { 'arxiv': 'https://openaccess.thecvf.com/content/CVPR2021/papers/Xu_Layout-Guided_Novel_View_Synthesis_From_a_Single_Indoor_Panorama_CVPR_2021_paper.pdf',
              'conf': 'CVPR 2021',
              'github': 'https://github.com/bluestyle97/PNVS',
              'title': 'Layout-Guided Novel View Synthesis From a Single '
                       'Indoor Panorama',
              'website': None},
            { 'arxiv': 'https://openaccess.thecvf.com/content/CVPR2021/papers/Xian_Space-Time_Neural_Irradiance_Fields_for_Free-Viewpoint_Video_CVPR_2021_paper.pdf',
              'conf': 'CVPR 2021',
              'github': None,
              'title': 'Space-Time Neural Irradiance Fields for Free-Viewpoint '
                       'Video',
              'website': None},
            { 'arxiv': 'https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_GeoSim_Realistic_Video_Simulation_via_Geometry-Aware_Composition_for_Self-Driving_CVPR_2021_paper.pdf',
              'conf': 'CVPR 2021',
              'github': None,
              'title': 'GeoSim: Realistic Video Simulation via Geometry-Aware '
                       'Composition for Self-Driving',
              'website': 'https://tmux.top/publication/geosim/'},
            { 'arxiv': 'https://openaccess.thecvf.com/content/CVPR2021/papers/Holynski_Animating_Pictures_With_Eulerian_Motion_Fields_CVPR_2021_paper.pdf',
              'conf': 'CVPR 2021',
              'github': None,
              'title': 'Animating Pictures With Eulerian Motion Fields',
              'website': 'https://eulerian.cs.washington.edu/'},
            { 'arxiv': 'https://arxiv.org/pdf/2108.02760',
              'conf': 'ICCV 2021',
              'github': 'https://github.com/kaanakan/slamp',
              'title': 'SLAMP: Stochastic Latent Appearance and Motion '
                       'Prediction',
              'website': 'https://kuis-ai.github.io/slamp/'},
            { 'arxiv': 'https://arxiv.org/pdf/2107.08037v2',
              'conf': 'NeurIPS 2021',
              'github': 'https://github.com/16lemoing/ccvs',
              'title': 'CCVS: Context-aware Controllable Video Synthesis',
              'website': 'https://16lemoing.github.io/ccvs/'},
            { 'arxiv': 'https://arxiv.org/pdf/2107.04619',
              'conf': 'ICLR 2021',
              'github': 'https://github.com/shgaurav1/DVG',
              'title': 'Diverse Video Generation using a Gaussian Process '
                       'Trigger',
              'website': None},
            { 'arxiv': 'https://arxiv.org/pdf/2106.13195',
              'conf': None,
              'github': 'https://github.com/google-research/fitvid',
              'title': 'FitVid: Overfitting in Pixel-Level Video Prediction',
              'website': None},
            { 'arxiv': 'https://arxiv.org/pdf/2106.04283',
              'conf': None,
              'github': 'https://github.com/lucidrains/NWT-pytorch',
              'title': 'NWT: Towards natural audio-to-video generation with '
                       'representation learning',
              'website': 'https://next-week-tonight.github.io/NWT_blog/'},
            { 'arxiv': 'https://arxiv.org/pdf/2104.14786',
              'conf': None,
              'github': 'https://github.com/darlinghang/st-nerf',
              'title': 'Editable Free-viewpoint Video Using a Layered Neural '
                       'Representation',
              'website': 'https://jiakai-zhang.github.io/st-nerf/'},
            { 'arxiv': 'https://arxiv.org/pdf/2104.15069',
              'conf': None,
              'github': 'https://github.com/snap-research/MoCoGAN-HD',
              'title': 'A Good Image Generator Is What You Need for '
                       'High-Resolution Video Synthesis',
              'website': 'https://bluer555.github.io/MoCoGAN-HD/'},
            { 'arxiv': 'https://arxiv.org/pdf/2104.14806',
              'conf': None,
              'github': 'https://github.com/mehdidc/DALLE_clip_score',
              'title': 'GODIVA: Generating Open-DomaIn Videos from nAtural '
                       'Descriptions',
              'website': None},
            { 'arxiv': 'https://arxiv.org/pdf/2104.14631',
              'conf': None,
              'github': 'https://github.com/sibozhang/Text2Video',
              'title': 'Text2Video: Text-driven Talking-head Video Synthesis '
                       'with Personalized Phoneme-Pose Dictionary',
              'website': None},
            { 'arxiv': 'https://arxiv.org/pdf/2104.11931',
              'conf': None,
              'github': 'https://github.com/wisdomdeng/AdaptiveRendering',
              'title': 'Adaptive Appearance Rendering',
              'website': None},
            { 'arxiv': 'https://arxiv.org/pdf/2104.07995',
              'conf': None,
              'github': 'https://github.com/FuxiVirtualHuman/Write-a-Speaker',
              'title': 'Write-a-speaker: Text-based Emotional and Rhythmic '
                       'Talking-head Generation',
              'website': None},
            { 'arxiv': 'https://arxiv.org/pdf/2103.01950',
              'conf': None,
              'github': 'https://github.com/mattiasxu/Video-VQVAE',
              'title': 'Predicting Video with VQVAE',
              'website': None},
            { 'arxiv': 'https://arxiv.org/pdf/2101.12195',
              'conf': 'CVPR 2021',
              'github': 'https://github.com/willi-menapace/PlayableVideoGeneration',
              'title': 'Playable Video Generation',
              'website': 'https://willi-menapace.github.io/playable-video-generation-website/'},
            { 'arxiv': 'https://arxiv.org/pdf/2012.09855',
              'conf': 'ICCV 2021',
              'github': 'https://github.com/google-research/google-research/tree/master/infinite_nature',
              'title': 'Infinite Nature: Perpetual View Generation of Natural '
                       'Scenes from a Single Image',
              'website': 'https://infinite-nature.github.io/'},
            { 'arxiv': 'https://arxiv.org/pdf/2010.08188',
              'conf': 'AAAI 2021',
              'github': 'https://github.com/psh01087/Vid-ODE',
              'title': 'Vid-ODE: Continuous-Time Video Generation with Neural '
                       'Ordinary Differential Equation',
              'website': 'https://psh01087.github.io/Vid-ODE/'},
            { 'arxiv': 'https://arxiv.org/pdf/2006.15327',
              'conf': 'ICML 2021',
              'github': 'https://github.com/roeiherz/AG2Video',
              'title': 'Compositional Video Synthesis with Action Graphs',
              'website': 'https://research.nvidia.com/labs/par/publication/sg2vid.html'},
            { 'arxiv': 'https://arxiv.org/pdf/2004.01823',
              'conf': 'WACV 2021',
              'github': 'https://github.com/amunozgarza/tsb-gan',
              'title': 'Temporal Shift GAN for Large Scale Video Generation',
              'website': None},
            { 'arxiv': 'https://arxiv.org/pdf/2102.06837',
              'conf': None,
              'github': None,
              'title': 'Learning Speech-driven 3D Conversational Gestures from '
                       'Video',
              'website': 'https://vcai.mpi-inf.mpg.de/projects/3d_speech_driven_gesture/'},
            { 'arxiv': 'https://arxiv.org/pdf/2102.09883',
              'conf': None,
              'github': None,
              'title': 'SLPC: a VRNN-based approach for stochastic lidar '
                       'prediction and completion in autonomous driving',
              'website': None},
            { 'arxiv': 'https://arxiv.org/pdf/2103.05669',
              'conf': None,
              'github': None,
              'title': 'Self-Supervision by Prediction for Object Discovery in '
                       'Videos',
              'website': None},
            { 'arxiv': 'https://arxiv.org/pdf/2104.03960',
              'conf': 'ICCV 2021',
              'github': 'https://github.com/lucidrains/siren-pytorch',
              'title': 'Modulated Periodic Activations for Generalizable Local '
                       'Functional Representations',
              'website': 'https://ishit.github.io/modsine/'},
            { 'arxiv': 'https://arxiv.org/pdf/2104.05940',
              'conf': None,
              'github': None,
              'title': 'Dynamic Texture Synthesis by Incorporating Long-range '
                       'Spatial and Temporal Correlations',
              'website': None},
            { 'arxiv': 'https://arxiv.org/pdf/2106.06561',
              'conf': None,
              'github': 'https://github.com/mchong6/GANsNRoses',
              'title': "GANs N' Roses: Stable, Controllable, Diverse Image to "
                       'Image Translation (works for videos too!)',
              'website': None},
            { 'arxiv': 'https://arxiv.org/pdf/2106.12423',
              'conf': 'NeurIPS 2021',
              'github': 'https://github.com/NVlabs/stylegan3',
              'title': 'Alias-Free Generative Adversarial Networks',
              'website': 'https://nvlabs.github.io/stylegan3/'},
            { 'arxiv': 'https://arxiv.org/pdf/2106.14879',
              'conf': None,
              'github': None,
              'title': 'Modeling Clothing as a Separate Layer for an '
                       'Animatable Human Avatar',
              'website': None},
            { 'arxiv': 'https://arxiv.org/pdf/2107.00650',
              'conf': 'NeurIPS 2021',
              'github': 'https://github.com/medhini/clip_it',
              'title': 'CLIP-It! Language-Guided Video Summarization',
              'website': 'https://medhini.github.io/clip_it/'},
            { 'arxiv': 'https://arxiv.org/pdf/2107.07713',
              'conf': None,
              'github': None,
              'title': 'Towards an Interpretable Latent Space in Structured '
                       'Models for Video Prediction',
              'website': None},
            { 'arxiv': 'https://arxiv.org/pdf/2108.04325',
              'conf': None,
              'github': None,
              'title': 'AnyoneNet: Synchronized Speech and Talking Head '
                       'Generation for Arbitrary Person',
              'website': 'https://xinshengwang.github.io/project/talking_head/'},
            { 'arxiv': 'https://arxiv.org/pdf/2108.06180',
              'conf': None,
              'github': 'https://github.com/jiafei1224/space',
              'title': 'SPACE: A Simulator for Physical Interactions and '
                       'Causal Learning in 3D Environments',
              'website': None},
            { 'arxiv': 'https://arxiv.org/pdf/2109.04683',
              'conf': None,
              'github': 'https://github.com/SamsonYuBaiJian/pip',
              'title': 'PIP: Physical Interaction Prediction via Mental '
                       'Simulation with Span Selection',
              'website': None},
            { 'arxiv': 'https://arxiv.org/pdf/2111.10337',
              'conf': 'CVPR 2022',
              'github': 'https://github.com/microsoft/xpretrain',
              'title': 'Advancing High-Resolution Video-Language '
                       'Representation with Large-Scale Video Transcriptions',
              'website': None},
            { 'arxiv': 'https://arxiv.org/pdf/2112.13548',
              'conf': 'ECCV 2022',
              'github': None,
              'title': 'Responsive Listening Head Generation: A Benchmark '
                       'Dataset and Baseline',
              'website': None},
            { 'arxiv': 'https://arxiv.org/pdf/2112.12761',
              'conf': 'CVPR 2022',
              'github': 'https://github.com/facebookresearch/banmo',
              'title': 'BANMo: Building Animatable 3D Neural Models from Many '
                       'Casual Videos',
              'website': 'https://banmo-www.github.io/'},
            { 'arxiv': 'https://arxiv.org/pdf/2112.10960',
              'conf': 'BMVC 2021',
              'github': None,
              'title': 'Continuous-Time Video Generation via Learning Motion '
                       'Dynamics with Neural ODE',
              'website': 'https://psh01087.github.io/MODE-GAN/'},
            { 'arxiv': 'https://arxiv.org/pdf/2112.10457',
              'conf': None,
              'github': 'https://github.com/or-toledano/animation-with-keypoint-mask',
              'title': 'Image Animation with Keypoint Mask',
              'website': None},
            { 'arxiv': 'https://arxiv.org/pdf/2112.10103',
              'conf': 'ECCV 2022',
              'github': 'https://github.com/JiahaoPlus/SAGA',
              'title': 'SAGA: Stochastic Whole-Body Grasping with Contact',
              'website': 'https://jiahaoplus.github.io/SAGA/saga.html'},
            { 'arxiv': 'https://arxiv.org/pdf/2112.09875',
              'conf': None,
              'github': None,
              'title': 'Adversarial Memory Networks for Action Prediction',
              'website': None},
            { 'arxiv': 'https://arxiv.org/pdf/2112.09529v1',
              'conf': None,
              'github': 'https://github.com/KUIS-AI-Tekalp-Research-Group/video-compression',
              'title': 'End-to-End Rate-Distortion Optimized Learned '
                       'Hierarchical Bi-Directional Video Compression',
              'website': None},
            { 'arxiv': 'https://arxiv.org/pdf/2112.09379',
              'conf': None,
              'github': None,
              'title': 'Enhanced Frame and Event-Based Simulator and '
                       'Event-Based Video Interpolation Network',
              'website': None},
            { 'arxiv': 'https://arxiv.org/pdf/2112.08913',
              'conf': 'AAAI 2022',
              'github': 'https://github.com/KT27-A/CSTP',
              'title': 'Discrete neural representations for explainable '
                       'anomaly detection',
              'website': None},
            { 'arxiv': 'https://arxiv.org/pdf/2112.03051',
              'conf': 'CVPR 2022',
              'github': None,
              'title': 'Controllable Animation of Fluid Elements in Still '
                       'Images',
              'website': 'https://controllable-cinemagraphs.github.io/'},
            { 'arxiv': 'https://arxiv.org/pdf/2112.02749',
              'conf': 'AAAI 2022',
              'github': 'https://github.com/FuxiVirtualHuman/AAAI22-one-shot-talking-face',
              'title': 'One-shot Talking Face Generation from Single-speaker '
                       'Audio-Visual Correlation Learning',
              'website': None},
            { 'arxiv': 'https://arxiv.org/pdf/2112.01517',
              'conf': 'SIGGRAPH Asia 2022',
              'github': 'https://github.com/zju3dv/enerf',
              'title': 'Efficient Neural Radiance Fields for Interactive '
                       'Free-viewpoint Video',
              'website': 'https://zju3dv.github.io/enerf/'},
            { 'arxiv': 'https://arxiv.org/abs/2112.01473',
              'conf': 'CVPR 2022',
              'github': 'https://github.com/princeton-computational-imaging/neural-point-light-fields',
              'title': 'Neural Point Light Fields',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2112.01161',
              'conf': 'NeurIPS 2020',
              'github': 'https://github.com/yjzhang96/UTI-VFI',
              'title': 'Video Frame Interpolation without Temporal Priors',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2111.15483',
              'conf': 'CVPR 2022',
              'github': 'https://github.com/danier97/ST-MFNet',
              'title': 'ST-MFNet: A Spatio-Temporal Multi-Flow Network for '
                       'Frame Interpolation',
              'website': 'https://danielism97.github.io/ST-MFNet'},
            { 'arxiv': 'https://arxiv.org/abs/2111.13817',
              'conf': 'CVPR 2022',
              'github': 'https://github.com/dvlab-research/vfiformer',
              'title': 'Video Frame Interpolation Transformer',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2111.12792',
              'conf': 'ECCV 2022',
              'github': 'https://github.com/shuhongchen/eisai-anime-interpolator',
              'title': 'Improving the Perceptual Quality of 2D Animation '
                       'Interpolation',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2111.12747',
              'conf': 'ECCV 2022',
              'github': 'https://github.com/Gabriel-Huang/Layered-Controllable-Video-Generation',
              'title': 'Layered Controllable Video Generation',
              'website': 'https://gabriel-huang.github.io/layered_controllable_video_generation/'},
            { 'arxiv': 'https://arxiv.org/abs/2111.12731',
              'conf': None,
              'github': 'https://github.com/guillaumerochette/humanviewsynthesis',
              'title': 'Human Pose Manipulation and Novel View Synthesis using '
                       'Differentiable Rendering',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2111.12301',
              'conf': None,
              'github': None,
              'title': 'Two-stage Rule-induction Visual Reasoning on RPMs with '
                       'an Application to Video Prediction',
              'website': None},
            { 'arxiv': 'http://export.arxiv.org/abs/2111.10916',
              'conf': None,
              'github': None,
              'title': 'Video Content Swapping Using GAN',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2111.10533',
              'conf': 'ECCV 2022',
              'github': 'https://github.com/HKBU-VSComputing/2022_ECCV_Temporal-MPI',
              'title': 'Temporal-MPI: Enabling Multi-Plane Images for Dynamic '
                       'Scene Modelling via Temporal Basis Learning',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2111.10233',
              'conf': None,
              'github': None,
              'title': 'Xp-GAN: Unsupervised Multi-object Controllable Video '
                       'Generation',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2111.06925',
              'conf': 'IJCV 2022',
              'github': None,
              'title': 'Action2video: Generating Videos of Human 3D Actions',
              'website': 'https://vision-and-learning-lab-ualberta.github.io/post/chuan_ijcv_2022/'},
            { 'arxiv': 'https://arxiv.org/abs/2111.05916',
              'conf': None,
              'github': None,
              'title': 'Dance In the Wild: Monocular Human Animation with '
                       'Neural Dynamic Appearance Synthesis',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2111.05916',
              'conf': None,
              'github': 'https://github.com/amazon-science/indoor-scene-generation-eai',
              'title': 'LUMINOUS: Indoor Scene Generation for Embodied AI '
                       'Challenges',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2111.01105',
              'conf': None,
              'github': None,
              'title': 'FREGAN : an application of generative adversarial '
                       'networks in enhancing the frame rate of videos',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2111.01029',
              'conf': None,
              'github': 'https://github.com/azuxmioy/Render-In-Between',
              'title': 'Render In-between: Motion Guided Video Synthesis for '
                       'Action Interpolation',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2111.00203',
              'conf': 'MM 2021',
              'github': 'https://github.com/wuhaozhe/style_avatar',
              'title': 'Imitating Arbitrary Talking Style for Realistic '
                       'Audio-DrivenTalking Face Synthesis',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2111.00203',
              'conf': None,
              'github': None,
              'title': 'TaylorSwiftNet: Taylor Driven Temporal Modeling for '
                       'Swift Future Frame Prediction',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2110.14147',
              'conf': 'TIP 2021',
              'github': None,
              'title': 'Image Comes Dancing with Collaborative Parsing-Flow '
                       'Video Synthesis',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2110.13746',
              'conf': None,
              'github': None,
              'title': 'H-NeRF: Neural Radiance Fields for Rendering and '
                       'Temporal Reconstruction of Humans in Motion',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2110.11795',
              'conf': 'ICVGIP 2021',
              'github': None,
              'title': 'HDRVideo-GAN: Deep Generative HDR Video Reconstruction',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2110.11746',
              'conf': 'WACV 2022',
              'github': 'https://github.com/verlab/CreatingAndReenacting_WACV_2022',
              'title': 'Creating and Reenacting Controllable 3D Humans with '
                       'Differentiable Rendering',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2110.11586',
              'conf': None,
              'github': None,
              'title': 'Wide and Narrow: Video Prediction from Context and '
                       'Motion',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2111.12792',
              'conf': 'WACV 2022',
              'github': 'https://github.com/skelemoa/mugl',
              'title': 'MUGL: Large Scale Multi Person Conditional Action '
                       'Generation with Locomotion',
              'website': 'https://skeleton.iiit.ac.in/mugl'},
            { 'arxiv': 'https://arxiv.org/abs/2110.11236',
              'conf': 'ICLR 2022',
              'github': None,
              'title': 'LARNet: Latent Action Representation for Human Action '
                       'Synthesis',
              'website': 'https://vpr-model.github.io/'},
            { 'arxiv': 'https://arxiv.org/abs/2110.09951',
              'conf': 'BMVC 2021',
              'github': None,
              'title': 'Talking Head Generation with Audio and Speech Related '
                       'Facial Action Units',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2110.09936',
              'conf': '3DV 2021',
              'github': 'https://github.com/dichotomies/NeuralDiff',
              'title': 'NeuralDiff: Segmenting 3D objects that move in '
                       'egocentric videos',
              'website': 'https://www.robots.ox.ac.uk/~vadim/neuraldiff/'},
            { 'arxiv': 'https://arxiv.org/abs/2110.08580',
              'conf': 'ICVGIP 2021',
              'github': None,
              'title': 'Intelligent Video Editing: Incorporating Modern '
                       'Talking Face Generation Algorithms in a Video Editor',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2110.07993',
              'conf': 'WACV 2022',
              'github': None,
              'title': 'Pose-guided Generative Adversarial Net for Novel View '
                       'Action Synthesis',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2110.05881',
              'conf': None,
              'github': None,
              'title': 'Fourier-based Video Prediction through Relational '
                       'Object Motion',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2110.04902',
              'conf': None,
              'github': None,
              'title': 'Synthetic Data for Multi-Parameter Camera-Based '
                       'Physiological Sensing',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2110.04710',
              'conf': None,
              'github': None,
              'title': 'Sketch Me A Video',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2110.02951',
              'conf': 'ICCV 2021',
              'github': 'https://github.com/zlai0/VideoAutoencoder',
              'title': 'Video Autoencoder: self-supervised disentanglement of '
                       'static 3D structure and motion',
              'website': 'https://zlai0.github.io/VideoAutoencoder/'},
            { 'arxiv': 'https://arxiv.org/abs/2110.03446',
              'conf': None,
              'github': None,
              'title': 'A Hierarchical Variational Neural Uncertainty Model '
                       'for Stochastic Video Prediction',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2110.00547',
              'conf': None,
              'github': None,
              'title': 'Self-Supervised Decomposition, Disentanglement and '
                       'Prediction of Video Sequences while Interpreting '
                       'Dynamics: A Koopman Perspective',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2109.12581',
              'conf': None,
              'github': None,
              'title': 'A Stacking Ensemble Approach for Supervised Video '
                       'Summarization',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2109.09913',
              'conf': 'ICCV 2021',
              'github': None,
              'title': 'Physics-based Human Motion Estimation and Synthesis '
                       'from Videos',
              'website': 'https://nv-tlabs.github.io/physics-pose-estimation-project-page/'},
            { 'arxiv': 'https://arxiv.org/abs/2109.08809',
              'conf': 'Datasets',
              'github': 'https://github.com/bcmi/video-harmonization-dataset-hyoutube',
              'title': 'HYouTube: Video Harmonization Dataset',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2109.08591',
              'conf': None,
              'github': 'https://github.com/nivha/single_video_generation',
              'title': 'Diverse Generation from a Single Video Made Possible',
              'website': 'https://nivha.github.io/vgpnn/'},
            { 'arxiv': 'https://arxiv.org/abs/2109.07448',
              'conf': None,
              'github': 'https://github.com/YoungJoongUNC/Neural_Human_Performer',
              'title': 'Neural Human Performer: Learning Generalizable '
                       'Radiance Fields for Human Performance Rendering',
              'website': 'https://youngjoongunc.github.io/nhp/'},
            { 'arxiv': 'https://arxiv.org/abs/2109.05864',
              'conf': None,
              'github': None,
              'title': 'Conditional MoCoGAN for Zero-Shot Video Generation',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2109.04843',
              'conf': None,
              'github': None,
              'title': 'Temporally Coherent Person Matting Trained on '
                       'Fake-Motion Dataset',
              'website': 'https://videoprocessing.github.io/person-matting'},
            { 'arxiv': 'https://arxiv.org/abs/2109.03292',
              'conf': None,
              'github': None,
              'title': 'Simple Video Generation using Neural ODEs',
              'website': 'https://voletiv.github.io/docs/presentations/20191213_Vancouver_NeurIPSW_EncODEDec.pdf'},
            { 'arxiv': 'https://arxiv.org/abs/2109.02625',
              'conf': None,
              'github': 'https://github.com/jnzs1836/era-vsum',
              'title': 'ERA: Entity Relationship Aware Video Summarization '
                       'with Wasserstein GAN',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2109.02216',
              'conf': 'ACM Multimedia 2021',
              'github': None,
              'title': 'Learning Fine-Grained Motion Embedding for Landscape '
                       'Animation',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2109.02081',
              'conf': None,
              'github': None,
              'title': 'Deep Person Generation: A Survey from the Perspective '
                       'of Face, Pose and Cloth Synthesis',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2109.00471',
              'conf': 'ICCV 2021',
              'github': 'https://github.com/fangchangma/sparse-to-dense',
              'title': 'Sparse to Dense Motion Transfer for Face Image '
                       'Animation',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2108.13408',
              'conf': 'ICCV 2021',
              'github': 'https://github.com/ken2576/deep-3dmask',
              'title': 'View Synthesis of Dynamic Scenes based on Deep 3D Mask '
                       'Volume',
              'website': 'https://cseweb.ucsd.edu//~viscomp/projects/ICCV21Deep/'},
            { 'arxiv': 'https://arxiv.org/abs/2108.12845',
              'conf': 'ICCV 2021',
              'github': 'https://github.com/donglao/videoinpainting',
              'title': 'Flow-Guided Video Inpainting with Scene Templates',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2108.08121',
              'conf': 'ICCV 2021',
              'github': 'https://github.com/mcg-nju/trace',
              'title': 'Target Adaptive Context Aggregation for Video Scene '
                       'Graph Generation',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2108.07938',
              'conf': 'ICCV 2021',
              'github': 'https://github.com/zhangchenxu528/FACIAL',
              'title': 'FACIAL: Synthesizing Dynamic Talking Face with '
                       'Implicit Attribute Learning',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2108.06815',
              'conf': 'ICCV 2021',
              'github': 'https://github.com/junheum/abme',
              'title': 'Asymmetric Bilateral Motion Estimation for Video Frame '
                       'Interpolation',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2108.06765',
              'conf': 'ICCV 2021',
              'github': None,
              'title': 'Occlusion-Aware Video Object Inpainting',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2108.05658',
              'conf': 'ECCV 2018',
              'github': 'https://github.com/yccyenchicheng/pytorch-VideoVAE',
              'title': 'Conditional Temporal Variational AutoEncoder for '
                       'Action Video Prediction',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2108.05650',
              'conf': 'IEEE TIP 2021IEEE TIP 2021',
              'github': None,
              'title': 'UniFaceGAN: A Unified Framework for Temporally '
                       'Consistent Facial Video Editing',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2108.05577',
              'conf': 'ACM MM 2021',
              'github': None,
              'title': 'iButter: Neural Interactive Bullet Time Generator for '
                       'Human Free-viewpoint Rendering',
              'website': 'https://aoliao12138.github.io/iButter/'},
            { 'arxiv': 'https://arxiv.org/abs/2108.04913',
              'conf': None,
              'github': None,
              'title': 'FLAME-in-NeRF : Neural control of Radiance Fields for '
                       'Free View Face Animation',
              'website': 'https://shahrukhathar.github.io/2021/08/12/FLAMEinNeRF.html'},
            { 'arxiv': 'https://arxiv.org/abs/2108.04294',
              'conf': 'ICCV 2021',
              'github': 'https://github.com/PardoAlejo/LearningToCut',
              'title': 'Learning to Cut by Watching Movies',
              'website': 'https://www.alejandropardo.net/publication/learning-to-cut/'},
            { 'arxiv': 'https://arxiv.org/abs/2108.03132',
              'conf': None,
              'github': None,
              'title': 'RockGPT: Reconstructing three-dimensional digital '
                       'rocks from single two-dimensional slice from the '
                       'perspective of video generation',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2108.00913',
              'conf': 'ACM MM 2021',
              'github': 'https://github.com/BIT-DA/I2V-GAN',
              'title': 'I2V-GAN: Unpaired Infrared-to-Visible Video '
                       'Translation',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2107.13766',
              'conf': None,
              'github': None,
              'title': 'Video Generation from Text Employing Latent Path '
                       'Construction for Temporal Modeling',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2107.09293',
              'conf': None,
              'github': 'https://github.com/wangsuzhen/Audio2Head',
              'title': 'Audio2Head: Audio-driven One-shot Talking-head '
                       'Generation with Natural Head Motion',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2107.09240',
              'conf': None,
              'github': None,
              'title': 'Generative Video Transformer: Can Objects be the '
                       'Words?',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2107.07224',
              'conf': None,
              'github': None,
              'title': 'StyleVideoGAN: A Temporal Generative Model using a '
                       'Pretrained StyleGAN',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2107.05113',
              'conf': None,
              'github': None,
              'title': 'LiveView: Dynamic Target-Centered MPI for View '
                       'Synthesis',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2107.04806',
              'conf': 'ACCV 2020',
              'github': 'https://github.com/sibozhang/Speech2Video',
              'title': 'Speech2Video: Cross-Modal Distillation for Speech to '
                       'Video Generation',
              'website': 'https://sites.google.com/view/sibozhang/speech2video'},
            { 'arxiv': 'https://arxiv.org/abs/2107.03120',
              'conf': 'ACM MM 2021',
              'github': None,
              'title': 'Cross-View Exocentric to Egocentric Video Synthesis',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2107.03109',
              'conf': None,
              'github': None,
              'title': 'Egocentric Videoconferencing',
              'website': 'http://gvv.mpi-inf.mpg.de/projects/EgoChat/'},
            { 'arxiv': 'https://arxiv.org/abs/2107.02790',
              'conf': 'ICCV 2021',
              'github': 'https://github.com/CompVis/ipoke',
              'title': 'iPOKE: Poking a Still Image for Controlled Stochastic '
                       'Video Synthesis',
              'website': 'https://compvis.github.io/ipoke/'},
            { 'arxiv': 'https://arxiv.org/abs/2106.14132',
              'conf': 'ICCV 2021',
              'github': 'https://github.com/SunYangtian/Neural-Human-Video-Rendering',
              'title': 'Robust Pose Transfer with Dynamic Details using Neural '
                       'Video Rendering',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2106.09051',
              'conf': None,
              'github': None,
              'title': 'Unsupervised Video Prediction from a Single Frame by '
                       'Estimating 3D Dynamic Scene Structure',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2106.08318',
              'conf': 'CVPR 2021',
              'github': None,
              'title': 'Gradient Forward-Propagation for Large-Scale Temporal '
                       'Video Modelling',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2106.05658',
              'conf': None,
              'github': 'https://github.com/neuripss2020/kccotgan',
              'title': 'Conditional COT-GAN for Video Prediction with Kernel '
                       'Smoothing',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2106.04185',
              'conf': 'CVPR 2021',
              'github': None,
              'title': 'LipSync3D: Data-Efficient Learning of Personalized 3D '
                       'Talking Faces from Video using Pose and Lighting '
                       'Normalization',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2106.04004',
              'conf': None,
              'github': None,
              'title': 'Task-Generic Hierarchical Human Motion Prior using '
                       'VAEs',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2106.03956',
              'conf': 'ICIP 2021',
              'github': 'https://github.com/google/stereo-magnification',
              'title': 'Novel View Video Prediction Using a Dual '
                       'Representation',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2106.03502',
              'conf': None,
              'github': None,
              'title': 'Efficient training for future video generation based '
                       'on hierarchical disentangled representation of latent '
                       'variables',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2106.02719',
              'conf': None,
              'github': None,
              'title': 'Hierarchical Video Generation for Complex Data',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2106.02328',
              'conf': 'FG 2021',
              'github': None,
              'title': 'Temporally coherent video anonymization through GAN '
                       'inpainting',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2106.02036',
              'conf': 'ICCV 2021',
              'github': 'https://github.com/facebookresearch/AVT',
              'title': 'Anticipative Video Transformer',
              'website': 'https://facebookresearch.github.io/AVT/'},
            { 'arxiv': 'https://arxiv.org/abs/2106.02019',
              'conf': 'SIGGRAPH Asia 2021',
              'github': 'https://github.com/lingjie0206/Neural_Actor_Main_Code',
              'title': 'Neural Actor: Neural Free-view Synthesis of Human '
                       'Actors with Pose Control',
              'website': 'https://vcai.mpi-inf.mpg.de/projects/NeuralActor/'},
            { 'arxiv': 'https://arxiv.org/abs/2105.14678',
              'conf': None,
              'github': None,
              'title': 'Image-to-Video Generation via 3D Facial Dynamics',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2105.13016',
              'conf': 'WACV 2022',
              'github': 'https://github.com/ztex08010518/Stylizing-3D-Scene',
              'title': 'Stylizing 3D Scene via Implicit Representation and '
                       'HyperNetwork',
              'website': 'https://ztex08010518.github.io/3dstyletransfer/'},
            { 'arxiv': 'https://arxiv.org/abs/2105.07673',
              'conf': None,
              'github': None,
              'title': 'EA-Net: Edge-Aware Network for Flow-based Video Frame '
                       'Interpolation',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2105.04637',
              'conf': None,
              'github': 'https://github.com/AIS-Bonn/Local_Freq_Transformer_Net',
              'title': 'Local Frequency Domain Transformer Networks for Video '
                       'Prediction',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2105.04551',
              'conf': 'CVPR 2021',
              'github': 'https://github.com/CompVis/image2video-synthesis-using-cINNs',
              'title': 'Stochastic Image-to-Video Synthesis using cINNs',
              'website': 'https://compvis.github.io/image2video-synthesis-using-cINNs/'},
            { 'arxiv': 'https://arxiv.org/abs/2105.04066',
              'conf': 'IEEE TPAMI 2021',
              'github': None,
              'title': 'Reconstructive Sequence-Graph Network for Video '
                       'Summarization',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2105.02799',
              'conf': None,
              'github': 'https://github.com/kschmeckpeper/opa',
              'title': 'Object-centric Video Prediction without Annotation',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2105.02742',
              'conf': None,
              'github': None,
              'title': 'Pose-Guided Sign Language Video GAN with Dynamic '
                       'Lambda',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2105.02195',
              'conf': None,
              'github': None,
              'title': 'Moving SLAM: Fully Unsupervised Deep Learning in '
                       'Non-Rigid Scenes',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2104.12357',
              'conf': 'IEEE (TMM)2021',
              'github': 'https://github.com/zhaoyuzhi/VCGAN',
              'title': 'VCGAN: Video Colorization with Hybrid Generative '
                       'Adversarial Network',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2104.12051',
              'conf': None,
              'github': None,
              'title': '3D-TalkEmo: Learning to Synthesize 3D Emotional '
                       'Talking Head',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2104.11216',
              'conf': 'CVPR 2021',
              'github': 'https://github.com/Sumith1896/motion2prog_release',
              'title': 'Hierarchical Motion Understanding via Motion Programs',
              'website': 'https://sumith1896.github.io/motion2prog/'},
            { 'arxiv': 'https://arxiv.org/abs/2104.11116',
              'conf': 'CVPR 2021',
              'github': 'https://github.com/Hangz-nju-cuhk/Talking-Face_PC-AVS',
              'title': 'Pose-Controllable Talking Face Generation by '
                       'Implicitly Modularized Audio-Visual Representation',
              'website': 'https://hangz-nju-cuhk.github.io/projects/PC-AVS'},
            { 'arxiv': 'https://arxiv.org/abs/2104.09762',
              'conf': 'CVPR 2021',
              'github': None,
              'title': 'Learning Semantic-Aware Dynamics for Video Prediction',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2104.09762',
              'conf': 'CVPR 2021',
              'github': 'https://github.com/facebookresearch/meshtalk',
              'title': 'MeshTalk: 3D Face Animation from Speech using '
                       'Cross-Modality Disentanglement',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2104.07473',
              'conf': 'CVPR 2020',
              'github': 'https://github.com/Mukosame/Zooming-Slow-Mo-CVPR-2020',
              'title': 'Zooming SlowMo: An Efficient One-Stage Framework for '
                       'Space-Time Video Super-Resolution',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2104.07452',
              'conf': 'CVPR 2021',
              'github': 'https://github.com/jixinya/EVP',
              'title': 'Audio-Driven Emotional Video Portraits',
              'website': 'https://jixinya.github.io/projects/evp/'},
            { 'arxiv': 'https://arxiv.org/abs/2104.06697',
              'conf': 'ICLR 2021',
              'github': 'https://github.com/1Konny/HVP',
              'title': 'Revisiting Hierarchical Approach for Persistent '
                       'Long-Term Video Prediction',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2104.02687',
              'conf': 'WACV 2022',
              'github': 'https://github.com/medhini/audio-video-textures',
              'title': 'Strumming to the Beat: Audio-Conditioned Contrastive '
                       'Video Textures',
              'website': 'https://medhini.github.io/audio_video_textures/'},
            { 'arxiv': 'https://arxiv.org/abs/2104.01517',
              'conf': None,
              'github': 'https://github.com/zhiqiiiiiii/PDWN_for_Video_Interp',
              'title': 'PDWN: Pyramid Deformable Warping Network for Video '
                       'Interpolation',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2104.01122',
              'conf': 'CVPR 2022',
              'github': None,
              'title': 'M3L: Language-based Video Editing via Multi-Modal '
                       'Multi-Level Transformers',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2104.00924',
              'conf': 'CVPR 2021',
              'github': 'https://github.com/sangmin-git/LMC-Memory',
              'title': 'Video Prediction Recalling Long-term Motion Context '
                       'via Memory Alignment Learning',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2104.02656',
              'conf': 'ICASSP 2021',
              'github': 'https://github.com/DelTA-Lab-IITK/AVG',
              'title': 'Collaborative Learning to Generate Audio-Video Jointly',
              'website': 'https://delta-lab-iitk.github.io/AVG/'},
            { 'arxiv': 'https://arxiv.org/abs/2103.17204',
              'conf': 'IJCV 2021',
              'github': 'https://github.com/verlab/ShapeAwareHumanRetargeting_IJCV_2021',
              'title': 'Long-Term Temporally Consistent Unpaired Video '
                       'Translation from Simulated Surgical 3D Data',
              'website': 'https://verlab.github.io/ShapeAwareHumanRetargeting_IJCV_2021/'},
            { 'arxiv': 'https://arxiv.org/abs/2103.15596',
              'conf': 'IJCV 2021',
              'github': None,
              'title': 'A Shape-Aware Retargeting Approach to Transfer Human '
                       'Motion and Appearance in Monocular Videos',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2103.11078',
              'conf': 'ICCV 2021',
              'github': 'https://github.com/YudongGuo/AD-NeRF',
              'title': 'AD-NeRF: Audio Driven Neural Radiance Fields for '
                       'Talking Head Synthesis',
              'website': 'https://yudongguo.github.io/ADNeRF/'},
            { 'arxiv': 'https://arxiv.org/abs/2103.10308',
              'conf': 'IPMI 2021',
              'github': None,
              'title': 'Future Frame Prediction for Robot-assisted Surgery',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2103.05842',
              'conf': None,
              'github': None,
              'title': 'Learning to compose 6-DoF omnidirectional videos using '
                       'multi-sphere images',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2103.04677',
              'conf': 'CVPR 2021',
              'github': 'https://github.com/CompVis/behavior-driven-video-synthesis',
              'title': 'Behavior-Driven Synthesis of Human Dynamics',
              'website': 'https://compvis.github.io/behavior-driven-video-synthesis/'},
            { 'arxiv': 'https://arxiv.org/abs/2103.04174',
              'conf': None,
              'github': None,
              'title': 'Greedy Hierarchical Variational Autoencoders for '
                       'Large-Scale Video Prediction',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2103.02984',
              'conf': 'AAAI 2021',
              'github': None,
              'title': 'Motion-blurred Video Interpolation and Extrapolation',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2103.02597',
              'conf': 'CVPR 2022',
              'github': 'https://github.com/facebookresearch/neural_3d_video',
              'title': 'Neural 3D Video Synthesis from Multi-view Video',
              'website': 'https://neural-3d-video.github.io/'},
            { 'arxiv': 'https://arxiv.org/abs/2103.02243',
              'conf': 'CVPR 2021',
              'github': 'https://github.com/thuml/MotionRNN',
              'title': 'MotionRNN: A Flexible Model for Video Prediction with '
                       'Spacetime-Varying Motions',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2102.13329',
              'conf': 'ICPR 2020',
              'github': None,
              'title': 'Dual-MTGAN: Stochastic and Deterministic Motion '
                       'Transfer for Image-to-Video Synthesis',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2102.09737',
              'conf': None,
              'github': None,
              'title': 'One Shot Audio to Animated Video Generation',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2102.09532',
              'conf': None,
              'github': 'https://github.com/vaibhavsaxena11/cwvae',
              'title': 'Clockwork Variational Autoencoders',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2102.05822',
              'conf': None,
              'github': 'https://github.com/AtlantixJJ/frame-difference-loss',
              'title': 'Frame Difference-Based Temporal Loss for Video '
                       'Stylization',
              'website': 'https://atlantixjj.github.io/FDB/'},
            { 'arxiv': 'https://arxiv.org/abs/2102.04680',
              'conf': 'NeurIPS Workshop 2020',
              'github': 'https://github.com/jdasam/traeumerAI',
              'title': 'TräumerAI: Dreaming Music with StyleGAN',
              'website': 'https://jdasam.github.io/traeumerAI_demo/'},
            { 'arxiv': 'https://arxiv.org/abs/2102.00863',
              'conf': None,
              'github': None,
              'title': 'Self-Supervised Equivariant Scene Synthesis from Video',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2101.12050',
              'conf': None,
              'github': None,
              'title': 'VAE^2: Preventing Posterior Collapse of Variational '
                       'Video Predictions in the Wild',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2101.08779',
              'conf': None,
              'github': 'https://github.com/google-research/mint',
              'title': 'AI Choreographer: Music Conditioned 3D Dance '
                       'Generation with AIST++',
              'website': 'https://google.github.io/aichoreographer/'},
            { 'arxiv': 'https://arxiv.org/abs/2101.07496',
              'conf': None,
              'github': None,
              'title': 'Disentangled Recurrent Wasserstein Autoencoder',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2101.03710',
              'conf': None,
              'github': 'https://github.com/Kibeom-Hong/ArrowGAN-pytorch',
              'title': 'ArrowGAN : Learning to Generate Videos by Learning '
                       'Arrow of Time',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2101.03049',
              'conf': None,
              'github': 'https://github.com/c1a1o1/InMoDeGAN-project',
              'title': 'InMoDeGAN: Interpretable Motion Decomposition '
                       'Generative Adversarial Network for Video Generation',
              'website': 'https://wyhsirius.github.io/InMoDeGAN/'},
            { 'arxiv': 'https://arxiv.org/abs/1903.10836',
              'conf': None,
              'github': None,
              'title': 'Personal Privacy Protection via Irrelevant Faces '
                       'Tracking and Pixelation in Video Live Streaming',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2105.06468',
              'conf': 'ICCV 2021',
              'github': 'https://github.com/gaochen315/DynamicNeRF',
              'title': 'Dynamic View Synthesis from Dynamic Monocular Video',
              'website': 'https://free-view-video.github.io/'},
            { 'arxiv': 'https://arxiv.org/abs/2012.12247',
              'conf': 'CVPR 2021',
              'github': 'https://github.com/facebookresearch/nonrigid_nerf',
              'title': 'Non-Rigid Neural Radiance Fields: Reconstruction and '
                       'Novel View Synthesis of a Dynamic Scene From Monocular '
                       'Video',
              'website': 'https://vcai.mpi-inf.mpg.de/projects/nonrigid_nerf/'}],
  '2022': [ { 'arxiv': 'https://arxiv.org/abs/2204.03458',
              'conf': 'NeurIPS 2022',
              'github': None,
              'title': 'Video Diffusion Models',
              'website': 'https://video-diffusion.github.io/'},
            { 'arxiv': 'https://arxiv.org/abs/2205.09853',
              'conf': 'NeurIPS 2022',
              'github': 'https://github.com/voletiv/mcvd-pytorch',
              'title': 'McVd: Masked Conditional Video Diffusion for '
                       'Prediction, Generation, and Interpolation',
              'website': 'https://mask-cond-video-diffusion.github.io'},
            { 'arxiv': 'https://arxiv.org/abs/2206.07696',
              'conf': 'TMLR 2022',
              'github': 'https://github.com/Tobi-r9/RaMViD',
              'title': 'Diffusion Models for Video Prediction and Infilling',
              'website': 'https://sites.google.com/view/video-diffusion-prediction'},
            { 'arxiv': 'https://openreview.net/forum?id=nJfylDvgzlq',
              'conf': 'ICLR 2023',
              'github': 'https://github.com/lucidrains/make-a-video-pytorch',
              'title': 'Make-A-Video: Text-to-Video Generation without '
                       'Text-Video Data',
              'website': 'https://makeavideo.studio'},
            { 'arxiv': 'https://arxiv.org/abs/2203.06605',
              'conf': 'CVPR 2022',
              'github': 'https://github.com/harlanhong/CVPR2022-DaGAN',
              'title': 'DaGAN: Depth-Aware Generative Adversarial Network for '
                       'Talking Head Video Generation',
              'website': 'https://harlanhong.github.io/publications/dagan.html'},
            { 'arxiv': 'https://arxiv.org/abs/2203.02573',
              'conf': 'CVPR 2022',
              'github': 'https://github.com/snap-research/MMVID',
              'title': 'Show Me What and Tell Me How: Video Synthesis via '
                       'Multimodal Conditioning',
              'website': 'https://snap-research.github.io/MMVID/'},
            { 'arxiv': 'https://arxiv.org/abs/2203.01914',
              'conf': 'CVPR 2022',
              'github': 'https://github.com/willi-menapace/PlayableEnvironments',
              'title': 'Playable Environments: Video Manipulation in Space and '
                       'Time',
              'website': 'https://willi-menapace.github.io/playable-environments-website/'},
            { 'arxiv': 'https://arxiv.org/abs/2207.05049',
              'conf': 'ECCV 2022',
              'github': 'https://github.com/fast-vid2vid/fast-vid2vid',
              'title': 'Fast-Vid2Vid: Spatial-Temporal Compression for '
                       'Video-to-Video Synthesis',
              'website': 'https://fast-vid2vid.github.io/'},
            { 'arxiv': 'https://arxiv.org/abs/2207.01696',
              'conf': 'ECCV 2022',
              'github': 'https://github.com/EricGuo5513/TM2T',
              'title': 'TM2T: Stochastic and Tokenized Modeling for the '
                       'Reciprocal Generation of 3D Human Motions and Texts',
              'website': 'https://ericguo5513.github.io/TM2T/'},
            { 'arxiv': 'https://arxiv.org/abs/2210.02303',
              'conf': None,
              'github': None,
              'title': 'Imagen Video: High Definition Video Generation with '
                       'Diffusion Models',
              'website': 'https://video-diffusion.github.io/'},
            { 'arxiv': 'https://arxiv.org/abs/2210.02399',
              'conf': None,
              'github': None,
              'title': 'Phenaki: Variable length video generation from open '
                       'domain textual description',
              'website': 'https://sites.research.google/phenaki/'},
            { 'arxiv': 'https://arxiv.org/abs/2212.11565',
              'conf': None,
              'github': 'https://github.com/showlab/Tune-A-Video',
              'title': 'Tune-A-Video: One-Shot Tuning of Image Diffusion '
                       'Models for Text-to-Video Generation',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2212.07413',
              'conf': None,
              'github': 'https://github.com/genforce/StyleSV',
              'title': 'Towards Smooth Video Composition',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2211.13221',
              'conf': None,
              'github': 'https://github.com/yingqinghe/lvdm',
              'title': 'Latent Video Diffusion Models for High-Fidelity Long '
                       'Video Generation',
              'website': 'https://yingqinghe.github.io/LVDM/'},
            { 'arxiv': 'https://arxiv.org/abs/2211.11743',
              'conf': None,
              'github': 'https://github.com/yanivnik/sinfusion-code',
              'title': 'SinFusion: Training Diffusion Models on a Single Image '
                       'or Video',
              'website': 'https://yanivnik.github.io/sinfusion/static/video_comparisons.html'},
            { 'arxiv': 'https://arxiv.org/abs/2210.16579',
              'conf': None,
              'github': 'https://github.com/bipashasen/INRV',
              'title': 'INR-V: A Continuous Representation Space for '
                       'Video-based Generative Tasks',
              'website': 'https://skymanaditya1.github.io/INRV/'},
            { 'arxiv': 'https://arxiv.org/abs/2210.04366',
              'conf': None,
              'github': 'https://github.com/patrickrperrine/comp-choreo',
              'title': 'Computational Choreography using Human Motion '
                       'Synthesis',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2210.02399',
              'conf': None,
              'github': 'https://github.com/lucidrains/phenaki-pytorch',
              'title': 'Phenaki: Variable Length Video Generation From Open '
                       'Domain Textual Description',
              'website': 'https://phenaki.video/'},
            { 'arxiv': 'https://arxiv.org/abs/2210.02396',
              'conf': None,
              'github': 'https://github.com/wilson1yan/teco',
              'title': 'Temporally Consistent Transformers for Video '
                       'Generation',
              'website': 'https://wilson1yan.github.io/teco/'},
            { 'arxiv': 'https://arxiv.org/abs/2208.07862',
              'conf': None,
              'github': 'https://github.com/arthur-qiu/stylefacev',
              'title': 'StyleFaceV: Face Video Generation via Decomposing and '
                       'Recomposing Pretrained StyleGAN3',
              'website': 'http://haonanqiu.com/projects/StyleFaceV.html'},
            { 'arxiv': 'https://arxiv.org/abs/2207.09814',
              'conf': None,
              'github': 'https://github.com/microsoft/nuwa',
              'title': 'NUWA-Infinity: Autoregressive over Autoregressive '
                       'Generation for Infinite Visual Synthesis',
              'website': 'https://nuwa-infinity.microsoft.com/'},
            { 'arxiv': 'https://arxiv.org/abs/2206.14797',
              'conf': None,
              'github': 'https://github.com/sherwinbahmani/3dvideogeneration/',
              'title': '3D-Aware Video Generation',
              'website': 'https://sherwinbahmani.github.io/3dvidgen/'},
            { 'arxiv': 'https://arxiv.org/abs/2206.04003',
              'conf': None,
              'github': 'https://github.com/wilson1yan/povt',
              'title': 'Patch-based Object-centric Transformers for Efficient '
                       'Video Generation',
              'website': 'https://sites.google.com/view/povt-public'},
            { 'arxiv': 'https://arxiv.org/abs/2206.03429',
              'conf': None,
              'github': 'https://github.com/nvlabs/long-video-gan',
              'title': 'Generating Long Videos of Dynamic Scenes',
              'website': 'https://www.timothybrooks.com/tech/long-video-gan/'},
            { 'arxiv': 'https://arxiv.org/abs/2206.01651',
              'conf': None,
              'github': 'https://github.com/hreynaud/dartagnan',
              'title': "D'ARTAGNAN: Counterfactual Video Generation",
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2205.15868',
              'conf': None,
              'github': 'https://github.com/thudm/cogvideo',
              'title': 'CogVideo: Large-scale Pretraining for Text-to-Video '
                       'Generation via Transformers',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2211.13221',
              'conf': None,
              'github': 'https://github.com/YingqingHe/LVDM',
              'title': 'Latent Video Diffusion Models for High-Fidelity Video '
                       'Generation With Arbitrary Lengths',
              'website': 'https://yingqinghe.github.io/LVDM/'},
            { 'arxiv': 'https://arxiv.org/abs/2211.11018',
              'conf': None,
              'github': None,
              'title': 'MagicVideo: Efficient Video Generation With Latent '
                       'Diffusion Models',
              'website': 'https://magicvideo.github.io/#'},
            { 'arxiv': 'https://arxiv.org/abs/2203.09481',
              'conf': None,
              'github': 'https://github.com/buggyyang/RVD',
              'title': 'Diffusion Probabilistic Modeling for Video Generation',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2205.11495',
              'conf': None,
              'github': 'https://github.com/plai-group/flexible-video-diffusion-modeling',
              'title': 'Flexible Diffusion Modeling of Long Videos',
              'website': 'https://fdmolv.github.io/'},
            { 'arxiv': 'https://arxiv.org/pdf/2204.03638',
              'conf': 'ECCV 2022',
              'github': 'https://github.com/songweige/tats',
              'title': 'Long Video Generation with Time-Agnostic VQGAN and '
                       'Time-Sensitive Transformer',
              'website': 'https://songweige.github.io/projects/tats/index.html'},
            { 'arxiv': 'https://arxiv.org/pdf/2203.09481',
              'conf': None,
              'github': 'https://github.com/buggyyang/rvd',
              'title': 'Diffusion Probabilistic Modeling for Video Generation',
              'website': None},
            { 'arxiv': 'https://arxiv.org/pdf/2203.04036',
              'conf': None,
              'github': 'https://github.com/OpenTalker/StyleHEAT',
              'title': 'StyleHEAT: One-Shot High-Resolution Editable Talking '
                       'Face Generation via Pre-trained StyleGAN',
              'website': 'https://feiiyin.github.io/StyleHEAT/'},
            { 'arxiv': 'https://arxiv.org/pdf/2202.10571',
              'conf': 'ICLR 2022',
              'github': 'https://github.com/sihyun-yu/digan',
              'title': 'Generating Videos with Dynamics-aware Implicit '
                       'Generative Adversarial Networks',
              'website': 'https://sihyun.me/digan/'},
            { 'arxiv': 'https://arxiv.org/pdf/2112.14683',
              'conf': 'CVPR 2022',
              'github': 'https://github.com/universome/stylegan-v',
              'title': 'StyleGAN-V: A Continuous Video Generator with the '
                       'Price, Image Quality and Perks of StyleGAN2',
              'website': 'https://universome.github.io/stylegan-v.html'},
            { 'arxiv': 'https://arxiv.org/pdf/2112.02815',
              'conf': 'CVPR 2022',
              'github': 'https://github.com/youncy-hu/mage',
              'title': 'Make It Move: Controllable Image-to-Video Generation '
                       'with Text Descriptions',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2212.13660',
              'conf': 'CVPR 2023',
              'github': 'https://github.com/wangkua1/nemo-cvpr2023',
              'title': 'NeMo: 3D Neural Motion Fields from Multiple Video '
                       'Instances of the Same Action',
              'website': 'https://sites.google.com/view/nemo-neural-motion-field'},
            { 'arxiv': 'https://arxiv.org/abs/2212.13525',
              'conf': 'WACV 2023',
              'github': 'https://github.com/eugenelet/CRFP',
              'title': 'Cross-Resolution Flow Propagation for Foveated Video '
                       'Super-Resolution',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2212.13056',
              'conf': None,
              'github': None,
              'title': 'MonoNeRF: Learning a Generalizable Dynamic Radiance '
                       'Field from Monocular Videos',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2212.11972',
              'conf': 'ICML 2023',
              'github': 'https://github.com/google-research/pix2seq',
              'title': 'Scalable Adaptive Computation for Iterative Generation',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2212.11642',
              'conf': None,
              'github': 'https://github.com/Ling-CF/MSPN',
              'title': 'Predictive Coding Based Multiscale Network with '
                       'Encoder-Decoder LSTM for Video Prediction',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2212.10550',
              'conf': None,
              'github': 'https://github.com/tijiang13/InstantAvatar',
              'title': 'InstantAvatar: Learning Avatars from Monocular Video '
                       'in 60 Seconds',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2212.09478',
              'conf': 'CVPR 2023',
              'github': 'https://github.com/researchmm/MM-Diffusion',
              'title': 'MM-Diffusion: Learning Multi-Modal Diffusion Models '
                       'for Joint Audio and Video Generation',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2212.08377',
              'conf': None,
              'github': 'https://github.com/zhengyuf/pointavatar',
              'title': 'PointAvatar: Deformable Point-based Head Avatars from '
                       'Videos',
              'website': 'https://zhengyuf.github.io/PointAvatar/'},
            { 'arxiv': 'https://arxiv.org/abs/2212.06384',
              'conf': 'ICLR 2023',
              'github': 'https://github.com/bytedance/pv3d',
              'title': 'PV3D: A 3D Generative Model for Portrait Video '
                       'Generation',
              'website': 'https://showlab.github.io/pv3d/'},
            { 'arxiv': 'https://arxiv.org/abs/2212.06026',
              'conf': 'ICPR 2022',
              'github': 'https://github.com/XiYe20/VPTR',
              'title': 'Video Prediction by Efficient Transformers',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2212.05199',
              'conf': 'CVPR 2023',
              'github': 'https://github.com/google-research/magvit',
              'title': 'MAGVIT: Masked Generative Video Transformer',
              'website': 'https://magvit.cs.cmu.edu/'},
            { 'arxiv': 'https://arxiv.org/abs/2212.04741',
              'conf': 'WACV 2023',
              'github': None,
              'title': 'Physically Plausible Animation of Human Upper Body '
                       'from a Single Image',
              'website': None},
            { 'arxiv': 'https://arxiv.org/pdf/2212.04655.pdf',
              'conf': None,
              'github': None,
              'title': 'MIMO Is All You Need : A Strong Multi-In-Multi-Out '
                       'Baseline for Video Prediction',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2212.03250',
              'conf': None,
              'github': None,
              'title': 'Neural Cell Video Synthesis via Optical-Flow Diffusion',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2212.02871',
              'conf': None,
              'github': None,
              'title': 'Video Object of Interest Segmentation',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2212.02350',
              'conf': 'NeurIPS 2022',
              'github': 'https://github.com/alvinliu0/ANGIE',
              'title': 'Audio-Driven Co-Speech Gesture Video Generation',
              'website': 'https://alvinliu0.github.io/projects/ANGIE'},
            { 'arxiv': 'https://arxiv.org/abs/2212.00235',
              'conf': 'AAAI 2023',
              'github': 'https://github.com/MKFMIKU/vidm',
              'title': 'VIDM: Video Implicit Diffusion Models',
              'website': 'https://kfmei.page/vidm/'},
            { 'arxiv': 'https://arxiv.org/abs/2212.00190',
              'conf': None,
              'github': 'https://github.com/fengres/mixvoxels',
              'title': 'Mixed Neural Voxels for Fast Multi-view Video '
                       'Synthesis',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2211.14758',
              'conf': 'SIGGRAPH Asia 2022',
              'github': 'https://github.com/OpenTalker/video-retalking',
              'title': 'VideoReTalking: Audio-based Lip Synchronization for '
                       'Talking Head Video Editing In the Wild',
              'website': 'https://opentalker.github.io/video-retalking/'},
            { 'arxiv': 'https://arxiv.org/abs/2211.14575',
              'conf': None,
              'github': None,
              'title': 'Randomized Conditional Flow Matching for Video '
                       'Prediction',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2211.14506',
              'conf': None,
              'github': 'https://github.com/Dorniwang/PD-FGC-inference',
              'title': 'Progressive Disentangled Representation Learning for '
                       'Fine-Grained Controllable Talking Head Synthesis',
              'website': 'https://dorniwang.github.io/PD-FGC/'},
            { 'arxiv': 'https://arxiv.org/abs/2211.14308',
              'conf': None,
              'github': None,
              'title': 'WALDO: Future Video Synthesis using Object Layer '
                       'Decomposition and Parametric Flow Prediction',
              'website': 'https://16lemoing.github.io/waldo/'},
            { 'arxiv': 'https://arxiv.org/abs/2211.14005',
              'conf': 'BMVC 2022',
              'github': 'https://github.com/visinf/fldr-vfi',
              'title': 'Efficient Feature Extraction for High-resolution Video '
                       'Frame Interpolation',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2211.13994',
              'conf': 'WACV 2023',
              'github': None,
              'title': 'Dynamic Neural Portraits',
              'website': 'https://michaildoukas.github.io/DynamicNeuralPortraits/'},
            { 'arxiv': 'https://arxiv.org/abs/2211.13319',
              'conf': 'CVPR 2023',
              'github': 'https://github.com/ubc-vision/Make-A-Story',
              'title': 'Make-A-Story: Visual Memory Conditioned Consistent '
                       'Story Generation',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2211.12824',
              'conf': 'CVPR 2023',
              'github': None,
              'title': 'Tell Me What Happened: Unifying Text-guided Video '
                       'Completion via Multimodal Masked Video Generation',
              'website': 'https://tvc-mmvg.github.io/'},
            { 'arxiv': 'https://arxiv.org/abs/2211.12782',
              'conf': 'CVPR 2023',
              'github': 'https://github.com/SeanChenxy/HandAvatar',
              'title': 'Hand Avatar: Free-Pose Hand Animation and Rendering '
                       'from Monocular Video',
              'website': 'https://seanchenxy.github.io/HandAvatarWeb/'},
            { 'arxiv': 'https://arxiv.org/abs/2211.12604#:~:text=22%20Nov%202022%5D-,SuperTran%3A%20Reference%20Based%20Video%20Transformer%20for%20Enhancing,Bitrate%20Streams%20in%20Real%20Time&text=This%20work%20focuses%20on%20low,video%20quality%20is%20severely%20compromised.',
              'conf': None,
              'github': None,
              'title': 'SuperTran: Reference Based Video Transformer for '
                       'Enhancing Low Bitrate Streams in Real Time',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2211.12436',
              'conf': None,
              'github': None,
              'title': 'Depth-Supervised NeRF for Multi-View RGB-D Operating '
                       'Room Images',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2211.12194',
              'conf': 'CVPR 2023',
              'github': 'https://github.com/OpenTalker/SadTalker',
              'title': 'SadTalker: Learning Realistic 3D Motion Coefficients '
                       'for Stylized Audio-Driven Single Image Talking Face '
                       'Animation',
              'website': 'https://sadtalker.github.io/'},
            { 'arxiv': 'https://arxiv.org/abs/2211.11903',
              'conf': 'CVPR 2023',
              'github': 'https://github.com/purvaten/FLEX',
              'title': 'FLEX: Full-Body Grasping Without Full-Body Grasps',
              'website': 'https://flex.cs.columbia.edu/'},
            { 'arxiv': 'https://arxiv.org/abs/2211.11423',
              'conf': 'CVPR 2023',
              'github': 'https://github.com/zzh-tech/BiT',
              'title': 'Blur Interpolation Transformer for Real-World Motion '
                       'from Blur',
              'website': 'https://zzh-tech.github.io/BiT/'},
            { 'arxiv': 'https://arxiv.org/abs/2211.11417',
              'conf': 'CVPR 2023',
              'github': 'https://github.com/IVRL/DyNCA',
              'title': 'DyNCA: Real-time Dynamic Texture Synthesis Using '
                       'Neural Cellular Automata',
              'website': 'https://dynca.github.io/'},
            { 'arxiv': 'https://arxiv.org/abs/2211.11309',
              'conf': None,
              'github': None,
              'title': 'H-VFI: Hierarchical Frame Interpolation for Videos '
                       'with Large Motions',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2211.10791',
              'conf': None,
              'github': None,
              'title': 'AdaFNIO: Adaptive Fourier Neural Interpolation '
                       'Operator for video frame interpolation',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2211.09809',
              'conf': None,
              'github': None,
              'title': 'SPACE: Speech-driven Portrait Animation with '
                       'Controllable Expression',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2211.08861',
              'conf': None,
              'github': None,
              'title': 'Creative divergent synthesis with generative models',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2211.08428',
              'conf': None,
              'github': None,
              'title': 'CaDM: Codec-aware Diffusion Modeling for '
                       'Neural-enhanced Video Streaming',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2211.07004',
              'conf': 'IEEE T-CSVT 2022',
              'github': 'https://github.com/RenYang-home/ALVC',
              'title': 'Advancing Learned Video Compression with In-loop Frame '
                       'Prediction',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2211.06119',
              'conf': None,
              'github': None,
              'title': 'SSGVS: Semantic Scene Graph-to-Video Synthesis',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2211.03889',
              'conf': None,
              'github': 'https://github.com/facebookresearch/cop3d',
              'title': 'Common Pets in 3D: Dynamic New-View Synthesis of '
                       'Real-Life Deformable Categories',
              'website': 'https://cop3d.github.io/'},
            { 'arxiv': 'https://arxiv.org/abs/2211.01639',
              'conf': 'IEEE T-CSVT 2022',
              'github': None,
              'title': 'Temporal Consistency Learning of inter-frames for '
                       'Video Super-Resolution',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2211.00924',
              'conf': 'AAAI 2022',
              'github': None,
              'title': 'SyncTalkFace: Talking Face Generation with Precise '
                       'Lip-Syncing via Audio-Lip Memory',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2210.15134',
              'conf': None,
              'github': None,
              'title': 'Learning Variational Motion Prior for Video-based '
                       'Motion Capture',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2210.14831',
              'conf': 'NeurIPS 2022',
              'github': 'https://github.com/AlgoHunt/StreamRF',
              'title': 'Streaming Radiance Fields for 3D Video Synthesis',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2210.13648',
              'conf': 'NeurIPS 2022',
              'github': None,
              'title': 'Learning to forecast vegetation greenness at fine '
                       'resolution over Africa with ConvLSTMs',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2210.13077',
              'conf': 'BMVC 2022',
              'github': None,
              'title': 'EpipolarNVS: leveraging on Epipolar geometry for '
                       'single-image Novel View Synthesis',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2210.12826',
              'conf': None,
              'github': 'https://github.com/pschaldenbrand/Text2Video',
              'title': 'Towards Real-Time Text2Video via CLIP-Guided, '
                       'Pixel-Level Optimization',
              'website': 'https://pschaldenbrand.github.io/text2video/'},
            { 'arxiv': 'https://arxiv.org/abs/2210.11182',
              'conf': 'ISWA',
              'github': None,
              'title': 'Facial Expression Video Generation Based-On '
                       'Spatio-temporal Convolutional GAN: FEV-GAN',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2210.08737',
              'conf': 'ECCV 2022',
              'github': 'https://github.com/VirtualFilmStudio/TVMCE',
              'title': 'Temporal and Contextual Transformer for Multi-Camera '
                       'Editing of TV Shows',
              'website': 'https://virtualfilmstudio.github.io/projects/multicam/'},
            { 'arxiv': 'https://arxiv.org/abs/2210.08577',
              'conf': None,
              'github': 'https://github.com/TempleRAIL/SOGMP',
              'title': 'Stochastic Occupancy Grid Map Prediction in Dynamic '
                       'Scenes',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2210.07181',
              'conf': 'ICML 2023',
              'github': None,
              'title': 'MonoNeRF: Learning Generalizable NeRFs from Monocular '
                       'Videos without Camera Pose',
              'website': 'https://oasisyang.github.io/mononerf/'},
            { 'arxiv': 'https://arxiv.org/abs/2210.06877',
              'conf': 'ICTAI 2022',
              'github': None,
              'title': 'Pre-Avatar: An Automatic Presentation Generation '
                       'Framework Leveraging Talking Avatar',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2210.06465',
              'conf': 'NeurIPS 2022',
              'github': None,
              'title': 'AniFaceGAN: Animatable 3D-Aware Face Image Generation '
                       'for Video Avatars',
              'website': 'https://yuewuhkust.github.io/AniFaceGAN/'},
            { 'arxiv': 'https://arxiv.org/abs/2210.06366',
              'conf': None,
              'github': None,
              'title': 'A Generalist Framework for Panoptic Segmentation of '
                       'Images and Videos',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2210.06096',
              'conf': 'CVPR 2023',
              'github': 'https://github.com/XinyuSun/MME',
              'title': 'Masked Motion Encoding for Self-Supervised Video '
                       'Representation Learning',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2210.05861',
              'conf': 'ICLR 2023',
              'github': 'https://github.com/pairlab/SlotFormer',
              'title': 'SlotFormer: Unsupervised Visual Dynamics Simulation '
                       'with Object-Centric Models',
              'website': 'https://slotformer.github.io/'},
            { 'arxiv': 'https://arxiv.org/abs/2210.05825',
              'conf': '3DV 2022',
              'github': 'https://github.com/KelestZ/CoRF',
              'title': 'Controllable Radiance Fields for Dynamic Face '
                       'Synthesis',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2210.05810',
              'conf': 'CVPR 2023',
              'github': None,
              'title': 'A unified model for continuous conditional video '
                       'prediction',
              'website': 'https://npvp.github.io/'},
            { 'arxiv': 'https://arxiv.org/abs/2210.04429',
              'conf': 'ICPR 2022',
              'github': None,
              'title': 'DeepHS-HDRVideo: Deep High Speed High Dynamic Range '
                       'Video Reconstruction',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2210.04154',
              'conf': None,
              'github': None,
              'title': 'Self-supervised Video Representation Learning with '
                       'Motion-Aware Masked Autoencoders',
              'website': 'https://github.com/happy-hsy/MotionMAE'},
            { 'arxiv': 'https://arxiv.org/abs/2210.03692v1',
              'conf': 'BMVC 2022',
              'github': None,
              'title': 'Compressing Video Calls using Synthetic Talking Heads',
              'website': 'https://cvit.iiit.ac.in/research/projects/cvit-projects/talking-video-compression'},
            { 'arxiv': 'https://arxiv.org/abs/2210.02872',
              'conf': None,
              'github': None,
              'title': 'Text-driven Video Prediction',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2210.02755',
              'conf': 'WACV 2023',
              'github': 'https://github.com/mdv3101/AVFR-Gan',
              'title': 'Audio-Visual Face Reenactment',
              'website': 'http://cvit.iiit.ac.in/research/projects/cvit-projects/avfr'},
            { 'arxiv': 'https://arxiv.org/abs/2210.02391',
              'conf': None,
              'github': None,
              'title': 'Geometry Driven Progressive Warping for One-Shot Face '
                       'Animation',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2210.01559',
              'conf': 'WACV 2023',
              'github': 'https://github.com/nihaomiao/WACV23_TSNet',
              'title': 'Cross-identity Video Motion Retargeting with Joint '
                       'Transformation and Synthesis',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2209.12475',
              'conf': 'ECCV 2022',
              'github': 'https://github.com/zmzhang1998/Real-RawVSR',
              'title': 'Real-RawVSR: Real-World Raw Video Super-Resolution '
                       'with a Benchmark Dataset',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2209.11224',
              'conf': 'SIGGRAPH Asia 2022',
              'github': 'https://github.com/williamyang1991/VToonify',
              'title': 'VToonify: Controllable High-Resolution Portrait Video '
                       'Style Transfer',
              'website': 'https://www.mmlab-ntu.com/project/vtoonify/'},
            { 'arxiv': 'https://arxiv.org/abs/2209.11693',
              'conf': 'IEEE',
              'github': 'https://github.com/nematoli/t3vip',
              'title': 'T3VIP: Transformation-based 3D Video Prediction',
              'website': 'http://t3vip.cs.uni-freiburg.de/'},
            { 'arxiv': 'https://arxiv.org/abs/2209.08896',
              'conf': 'SIGGRAPH Asia 2022',
              'github': 'https://github.com/drinkingcoder/NeuralMarker',
              'title': 'NeuralMarker: A Framework for Learning General Marker '
                       'Correspondence',
              'website': 'https://drinkingcoder.github.io/publication/neuralmarker/'},
            { 'arxiv': 'https://arxiv.org/abs/2209.08795',
              'conf': None,
              'github': None,
              'title': 'AutoLV: Automatic Lecture Video Generator',
              'website': 'https://www.youtube.com/watch?v=cY6TYkI0cog'},
            { 'arxiv': 'https://arxiv.org/abs/2209.08289',
              'conf': None,
              'github': None,
              'title': 'Continuously Controllable Facial Expression Editing in '
                       'Talking Face Videos',
              'website': 'https://www.youtube.com/watch?v=WD-bNVya6kM'},
            { 'arxiv': 'https://arxiv.org/abs/2209.07923',
              'conf': 'ECCV 2022',
              'github': 'https://github.com/BGU-CS-VIL/DeepMCBM',
              'title': 'A Deep Moving-camera Background Model',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2209.07143',
              'conf': 'ICIP 2022',
              'github': None,
              'title': 'HARP: Autoregressive Latent Video Prediction with '
                       'High-Fidelity Image Generator',
              'website': 'https://sites.google.com/view/harp-videos/home'},
            { 'arxiv': 'https://arxiv.org/abs/2209.04252',
              'conf': 'ACM Multimedia 2022',
              'github': 'https://github.com/MohammedAlghamdi/talking-heads-acm-mm',
              'title': 'Talking Head from Speech Audio using a Pre-trained '
                       'Image Generator',
              'website': 'https://mohammedalghamdi.github.io/talking-heads-acm-mm/'},
            { 'arxiv': 'https://arxiv.org/abs/2209.03138',
              'conf': 'WACV 2023',
              'github': 'https://github.com/suhwan-cho/tmo',
              'title': 'Treating Motion as Option to Reduce Motion Dependency '
                       'in Unsupervised Video Object Segmentation',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2209.01470',
              'conf': 'CVPR 2023',
              'github': None,
              'title': 'Neural Sign Reenactor: Deep Photorealistic Sign '
                       'Language Retargeting',
              'website': 'https://www.youtube.com/watch?v=xKAfguacOkE'},
            { 'arxiv': 'https://arxiv.org/abs/2209.00475',
              'conf': 'ACMMM 2022',
              'github': None,
              'title': 'REMOT: A Region-to-Whole Framework for Realistic Human '
                       'Motion Transfer',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2209.00185',
              'conf': 'ACM conference on the Foundations of Digital Games',
              'github': None,
              'title': 'SketchBetween: Video-to-Video Synthesis for Sprite '
                       'Animation via Sketches',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2208.13717',
              'conf': None,
              'github': None,
              'title': 'StableFace: Analyzing and Improving Motion Stability '
                       'for Talking Face Generation',
              'website': 'https://stable-face.github.io/'},
            { 'arxiv': 'https://arxiv.org/abs/2208.12801',
              'conf': None,
              'github': 'https://github.com/SHI-Labs/VMFormer',
              'title': 'VMFormer: End-to-End Video Matting with Transformer',
              'website': 'https://chrisjuniorli.github.io/project/VMFormer/'},
            { 'arxiv': 'https://arxiv.org/abs/2208.11905',
              'conf': None,
              'github': 'https://github.com/Talegqz/neural_novel_actor',
              'title': 'Neural Novel Actor: Learning a Generalized Animatable '
                       'Neural Representation for Human Actors',
              'website': 'https://talegqz.github.io/neural_novel_actor/'},
            { 'arxiv': 'https://arxiv.org/abs/2208.10922',
              'conf': None,
              'github': None,
              'title': 'StyleTalker: One-shot Style-based Audio-driven Talking '
                       'Head Video Generation',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2208.09796',
              'conf': 'WACV 2023',
              'github': None,
              'title': 'Towards MOOCs for Lipreading: Using Synthetic Talking '
                       'Heads to Train Humans in Lipreading at Scale',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2208.09463',
              'conf': 'ISMAR 2022',
              'github': 'https://github.com/NagabhushanSN95/DeCOMPnet',
              'title': 'Temporal View Synthesis of Dynamic Scenes through 3D '
                       'Object Motion Estimation with Multi-Plane Images',
              'website': 'https://nagabhushansn95.github.io/publications/2022/DeCOMPnet.html'},
            { 'arxiv': 'https://arxiv.org/abs/2208.09411',
              'conf': None,
              'github': None,
              'title': 'Wildfire Forecasting with Satellite Images and Deep '
                       'Generative Model',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2208.09127',
              'conf': 'ECCV 2022',
              'github': None,
              'title': 'Video Interpolation by Event-driven Anisotropic '
                       'Adjustment of Optical Flow',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2208.08118',
              'conf': 'ACMMM 2022',
              'github': 'https://github.com/Sindhu-Hegde/video-super-resolver',
              'title': 'Extreme-scale Talking-Face Video Upsampling with '
                       'Audio-Visual Priors',
              'website': 'http://cvit.iiit.ac.in/research/projects/cvit-projects/talking-face-video-upsampling'},
            { 'arxiv': 'https://arxiv.org/abs/2208.06807',
              'conf': None,
              'github': None,
              'title': 'Semi-Supervised Video Inpainting with Cycle '
                       'Consistency Constraints',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2208.06702',
              'conf': None,
              'github': None,
              'title': 'UAV-CROWD: Violent and non-violent crowd activity '
                       'simulator from the perspective of UAV',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2208.05701',
              'conf': 'ACMHCI',
              'github': None,
              'title': 'Cine-AI: Generating Video Game Cutscenes in the Style '
                       'of Human Directors',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2208.05617',
              'conf': None,
              'github': 'https://github.com/researchmm/language-guided-animation',
              'title': 'Language-Guided Face Animation by Recurrent '
                       'StyleGAN-based Generator',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2208.04303',
              'conf': None,
              'github': None,
              'title': 'Boosting neural video codecs by exploiting '
                       'hierarchical redundancy',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2208.03742',
              'conf': None,
              'github': None,
              'title': 'PS-NeRV: Patch-wise Stylized Neural Representations '
                       'for Videos',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2208.03244',
              'conf': 'CHI EA 2021',
              'github': 'https://github.com/mrebol/Gestures-From-Speech',
              'title': 'Real-time Gesture Animation Generation from Speech for '
                       'Virtual Human Interaction',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2207.13670',
              'conf': None,
              'github': None,
              'title': 'Meta-Interpolation: Time-Arbitrary Frame Interpolation '
                       'via Dual Meta-Learning',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2207.13374',
              'conf': 'ECCV 2022',
              'github': 'https://github.com/sollynoay/MMP-RNN',
              'title': 'Efficient Video Deblurring Guided by Motion Magnitude',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2207.12305',
              'conf': None,
              'github': None,
              'title': 'Error-Aware Spatial Ensembles for Video Frame '
                       'Interpolation',
              'website': 'https://www.youtube.com/watch?v=_32GNANSr5U'},
            { 'arxiv': 'https://arxiv.org/abs/2207.11770',
              'conf': 'ECCV 2022',
              'github': 'https://github.com/sstzal/DFRF',
              'title': 'Learning Dynamic Facial Radiance Fields for Few-Shot '
                       'Talking Head Synthesis',
              'website': 'https://sstzal.github.io/DFRF/'},
            { 'arxiv': 'https://arxiv.org/abs/2207.11148',
              'conf': 'ECCV 2022',
              'github': None,
              'title': 'InfiniteNature-Zero: Learning Perpetual View '
                       'Generation of Natural Scenes from Single Images',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2207.11075',
              'conf': 'ECCV 2022 Oral',
              'github': 'https://github.com/megvii-research/RealFlow',
              'title': 'RealFlow: EM-based Realistic Optical Flow Dataset '
                       'Generation from Videos',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2207.10765',
              'conf': 'ECCV 2022',
              'github': 'https://github.com/caojiezhang/DAVSR',
              'title': 'Towards Interpretable Video Super-Resolution via '
                       'Alternating Optimization',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2207.10391',
              'conf': 'ECCV 2022',
              'github': 'https://github.com/JaeYeonKang/ECFVI',
              'title': 'Error Compensation Framework for Flow-Guided Video '
                       'Inpainting',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2207.10123',
              'conf': 'ECCV 2022',
              'github': 'https://github.com/zzh-tech/Animation-from-Blur',
              'title': 'Animation from Blur: Multi-modal Blur Decomposition '
                       'with Motion Guidance',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2207.09048',
              'conf': 'CVPR 2022 Oral',
              'github': 'https://github.com/researchmm/TTVSR',
              'title': 'TTVFI: Learning Trajectory-Aware Transformer for Video '
                       'Frame Interpolation',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2207.08813',
              'conf': None,
              'github': None,
              'title': 'Audio Input Generates Continuous Frames to Synthesize '
                       'Facial Video Using Generative Adiversarial Networks',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2207.06763',
              'conf': 'ACMMM 2022',
              'github': None,
              'title': 'Neighbor Correspondence Matching for Flow-based Video '
                       'Frame Synthesis',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2207.06345',
              'conf': 'ACMMM 2022',
              'github': None,
              'title': 'You Only Align Once: Bidirectional Interaction for '
                       'Spatial-Temporal Video Super-Resolution',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2207.05315',
              'conf': None,
              'github': 'https://github.com/NYCU-MAPL/CANF-VC',
              'title': 'CANF-VC: Conditional Augmented Normalizing Flows for '
                       'Video Compression',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2207.04566',
              'conf': None,
              'github': None,
              'title': 'A Probabilistic Model Of Interaction Dynamics for '
                       'Dyadic Face-to-Face Settings',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2207.04132',
              'conf': None,
              'github': None,
              'title': 'Cross-Attention Transformer for Video Interpolation',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2207.03714',
              'conf': None,
              'github': None,
              'title': 'Jointly Harnessing Prior Structures and Temporal '
                       'Consistency for Sign Language Video Generation',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2207.02206',
              'conf': 'NeurIPS 2022',
              'github': 'https://github.com/jyxarthur/oclr_model',
              'title': 'Segmenting Moving Objects via an Object-Centric '
                       'Layered Representation',
              'website': 'https://www.robots.ox.ac.uk/~vgg/research/oclr/'},
            { 'arxiv': 'https://arxiv.org/abs/2206.13502',
              'conf': 'CVPR 2022',
              'github': None,
              'title': 'Programmatic Concept Learning for Human Motion '
                       'Description and Synthesis',
              'website': 'https://sumith1896.github.io/motion-concepts/'},
            { 'arxiv': 'https://arxiv.org/abs/2206.13454',
              'conf': 'CVPR 2022',
              'github': 'https://github.com/YueWuHKUST/CVPR2022-Optimizing-Video-Prediction-via-Video-Frame-Interpolation',
              'title': 'Optimizing Video Prediction via Video Frame '
                       'Interpolation',
              'website': 'https://yuewuhkust.github.io/OVP_VFI/'},
            { 'arxiv': 'https://arxiv.org/abs/2206.12837',
              'conf': 'ACMMM 2022',
              'github': 'https://github.com/megvii-research/MM2022-ViCoPerceptualHeadGeneration',
              'title': 'Perceptual Conversational Head Generation with '
                       'Regularized Driver and Enhanced Renderer',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2206.11894',
              'conf': None,
              'github': 'https://github.com/agrimgupta92/maskvit',
              'title': 'MaskViT: Masked Visual Pre-Training for Video '
                       'Prediction',
              'website': 'https://maskedvit.github.io/'},
            { 'arxiv': 'https://arxiv.org/abs/2206.08572',
              'conf': 'WACV 2023',
              'github': 'https://github.com/srcn-ivl/EBME',
              'title': 'Enhanced Bi-directional Motion Estimation for Video '
                       'Frame Interpolation',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2206.04523',
              'conf': None,
              'github': None,
              'title': 'Face-Dubbing++: Lip-Synchronous, Voice Preserving '
                       'Translation of Videos',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2206.04381',
              'conf': 'CVPR 2022',
              'github': 'https://github.com/ZhengChang467/STIPHR',
              'title': 'STIP: A SpatioTemporal Information-Preserving and '
                       'Perception-Augmented Model for High-Resolution Video '
                       'Prediction',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2206.04231v2',
              'conf': None,
              'github': None,
              'title': 'JNMR: Joint Non-linear Motion Regression for Video '
                       'Frame Interpolation',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2206.05099',
              'conf': 'CVPR 2022',
              'github': 'https://github.com/A4Bio/SimVP-Simpler-yet-Better-Video-Prediction',
              'title': 'SimVP: Simpler yet Better Video Prediction',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2206.02146',
              'conf': 'NeurIPS 2022',
              'github': 'https://github.com/JingyunLiang/RVRT',
              'title': 'Recurrent Video Restoration Transformer with Guided '
                       'Deformable Attention',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2206.00735',
              'conf': 'ICPR 2022',
              'github': None,
              'title': 'Cascaded Video Generation for Videos In-the-Wild',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2205.15838',
              'conf': None,
              'github': 'https://github.com/ChikaYan/d2nerf',
              'title': 'D$^2$NeRF: Self-Supervised Decoupling of Dynamic and '
                       'Static Objects from a Monocular Video',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2205.15361',
              'conf': 'CVPR 2022',
              'github': None,
              'title': 'TubeFormer-DeepLab: Video Mask Transformer',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2205.14620',
              'conf': 'CVPR 2022',
              'github': 'https://github.com/ltkong218/IFRNet',
              'title': 'IFRNet: Intermediate Feature Refine Network for '
                       'Efficient Frame Interpolation',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2205.14574',
              'conf': None,
              'github': None,
              'title': 'Feature-Aligned Video Raindrop Removal with Temporal '
                       'Constraints',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2205.14022',
              'conf': 'CVPR 2022',
              'github': 'https://github.com/gongda0e/FUTR',
              'title': 'Future Transformer for Long-term Action Anticipation',
              'website': 'http://cvlab.postech.ac.kr/research/FUTR/'},
            { 'arxiv': 'https://arxiv.org/abs/2205.13996',
              'conf': None,
              'github': None,
              'title': 'Video2StyleGAN: Disentangling Local and Global '
                       'Variations in a Video',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2205.10368',
              'conf': None,
              'github': None,
              'title': 'Automatic Generation of Synthetic Colonoscopy Videos '
                       'for Domain Randomization',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2205.10367',
              'conf': None,
              'github': 'https://github.com/hollerm/generator_based_motion_isolation',
              'title': 'Latent-space disentanglement with untrained generator '
                       'networks for the isolation of different motion types '
                       'in video data',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2205.07230',
              'conf': 'CVPR 2022',
              'github': 'https://github.com/dvlab-research/VFIformer',
              'title': 'Video Frame Interpolation with Transformer',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2205.06723',
              'conf': 'NTIRE',
              'github': None,
              'title': 'Multi-encoder Network for Parameter Reduction of a '
                       'Kernel-based Interpolation Architecture',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2205.05725',
              'conf': 'CVPR 2022',
              'github': None,
              'title': 'Diverse Video Generation from a Single Video',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2205.05609',
              'conf': 'AICC',
              'github': None,
              'title': 'Video-ReTime: Learning Temporally Varying Speediness '
                       'for Time Remapping',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2205.05264',
              'conf': None,
              'github': 'https://github.com/hhhhhumengshun/SFI-STVR',
              'title': 'Spatial-Temporal Space Hand-in-Hand: Spatial-Temporal '
                       'Video Super-Resolution via Cycle-Projected Mutual '
                       'Learning',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2205.04519',
              'conf': 'CVPR 2022',
              'github': 'https://github.com/JurijsNazarovs/warping_node',
              'title': 'Image2Gif: Generating Continuous Realistic Animations '
                       'with Warping NODEs',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2205.03599',
              'conf': None,
              'github': None,
              'title': 'GAN-Based Multi-View Video Coding with Spatio-Temporal '
                       'EPI Reconstruction',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2205.02538v1',
              'conf': None,
              'github': None,
              'title': 'Parametric Reshaping of Portraits in Videos',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2205.02084',
              'conf': 'ECCV 2022',
              'github': 'https://github.com/zzyunzhi/vest',
              'title': 'Video Extrapolation in Space and Time',
              'website': 'https://cs.stanford.edu/~yzzhang/projects/vest/'},
            { 'arxiv': 'https://arxiv.org/abs/2205.01924',
              'conf': None,
              'github': None,
              'title': 'Zero-Episode Few-Shot Contrastive Predictive Coding: '
                       'Solving intelligence tests without prior training',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2205.01373',
              'conf': None,
              'github': None,
              'title': 'Copy Motion From One to Another: Fake Motion Video '
                       'Generation',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2204.14030',
              'conf': 'WACV 2023',
              'github': None,
              'title': 'Neural Implicit Representations for Physical Parameter '
                       'Inference from a Single Video',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2110.09951',
              'conf': 'BMVC 2021',
              'github': None,
              'title': 'Talking Head Generation Driven by Speech-Related '
                       'Facial Action Units and Audio- Based on Multimodal '
                       'Representation Fusion',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2204.12151',
              'conf': 'CVPR 2022 Oral',
              'github': 'https://github.com/luxiangju-PersonAI/ClothFormer',
              'title': 'ClothFormer:Taming Video Virtual Try-on in All Module',
              'website': 'https://cloth-former.github.io/'},
            { 'arxiv': 'https://arxiv.org/abs/2204.10321',
              'conf': None,
              'github': 'https://github.com/atonderski/future-object-detection',
              'title': 'Future Object Detection with Spatiotemporal '
                       'Transformers',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2204.09456',
              'conf': 'TPAMI',
              'github': None,
              'title': 'STAU: A SpatioTemporal-Aware Unit for Video Prediction '
                       'and Beyond',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2204.09273',
              'conf': 'ECCV 2022',
              'github': None,
              'title': 'Sound-Guided Semantic Video Generation',
              'website': 'https://kuai-lab.github.io/eccv2022sound/'},
            { 'arxiv': 'https://arxiv.org/abs/2204.08874',
              'conf': None,
              'github': None,
              'title': 'Less than Few: Self-Shot Video Instance Segmentation',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2204.08451',
              'conf': None,
              'github': 'https://github.com/evonneng/learning2listen',
              'title': 'Learning to Listen: Modeling Non-Deterministic Dyadic '
                       'Facial Motion',
              'website': 'https://evonneng.github.io/learning2listen/'},
            { 'arxiv': 'https://arxiv.org/abs/2204.08058',
              'conf': None,
              'github': 'https://github.com/mugen-org/MUGEN_baseline',
              'title': 'MUGEN: A Playground for Video-Audio-Text Multimodal '
                       'Understanding and GENeration',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2204.06558',
              'conf': None,
              'github': None,
              'title': 'Controllable Video Generation through Global and Local '
                       'Motion Dynamics',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2204.06180',
              'conf': None,
              'github': None,
              'title': 'Dynamic Neural Textures: Generating Talking-Face '
                       'Videos with Continuously Controllable Expressions',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2204.06171',
              'conf': 'ITSC',
              'github': None,
              'title': 'Self-Supervised Traffic Advisors: Distributed, '
                       'Multi-view Traffic Prediction for Smart Cities',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2204.05018',
              'conf': 'CVPR 2022',
              'github': 'https://github.com/JialeTao/DAM',
              'title': 'Structure-Aware Motion Transfer with Deformable Anchor '
                       'Model',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2204.04435',
              'conf': None,
              'github': None,
              'title': 'HSTR-Net: High Spatio-Temporal Resolution Video '
                       'Generation For Wide Area Surveillance',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2204.03648',
              'conf': 'CVPR 2023',
              'github': 'https://github.com/adobe-research/sunstage',
              'title': 'SunStage: Portrait Reconstruction and Relighting using '
                       'the Sun as a Light Stage',
              'website': 'https://sunstage.cs.washington.edu/'},
            { 'arxiv': 'https://arxiv.org/abs/2204.03513',
              'conf': 'CVPR 2022',
              'github': 'https://github.com/feinanshan/M2M_VFI',
              'title': 'Many-to-many Splatting for Efficient Video Frame '
                       'Interpolation',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2204.02957',
              'conf': 'CVPR 2022',
              'github': 'https://github.com/CVMI-Lab/VideoDemoireing',
              'title': 'Video Demoireing with Relation-Based Temporal '
                       'Consistency',
              'website': 'https://daipengwa.github.io/VDmoire_ProjectPage/'},
            { 'arxiv': 'https://arxiv.org/abs/2204.01218',
              'conf': None,
              'github': None,
              'title': 'Neural Rendering of Humans in Novel View and Pose from '
                       'Monocular Video',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2203.16875',
              'conf': 'TPAMI 2022',
              'github': 'https://github.com/gaoxiangjun/MPS-NeRF',
              'title': 'MPS-NeRF: Generalizable 3D Human Rendering from '
                       'Multiview Images',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2203.16490',
              'conf': None,
              'github': None,
              'title': 'Foveation-based Deep Video Compression without Motion '
                       'Search',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2203.16084',
              'conf': 'CVPR 2022',
              'github': 'https://github.com/ZhengChang467/STIPHR',
              'title': 'STRPM: A Spatiotemporal Residual Predictive Model for '
                       'High-Resolution Video Prediction',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2203.15958',
              'conf': 'CVPR 2022',
              'github': 'https://github.com/cnnlstm/FSLSD_HiRes',
              'title': 'High-resolution Face Swapping via Latent Semantics '
                       'Disentanglement',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2203.15836',
              'conf': 'ICPR 2022',
              'github': 'https://github.com/XiYe20/VPTR',
              'title': 'VPTR: Efficient Transformers for Video Prediction',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2203.15427',
              'conf': 'CVPR 2022',
              'github': None,
              'title': 'Long-term Video Frame Interpolation via Feature '
                       'Propagation',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2203.15354',
              'conf': None,
              'github': None,
              'title': 'Signing at Scale: Learning to Co-Articulate Signs for '
                       'Large-Scale Photo-Realistic Sign Language Production',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2203.15320',
              'conf': 'CVPR 2022',
              'github': None,
              'title': 'Dressing in the Wild by Watching Dance Videos',
              'website': 'https://awesome-wflow.github.io/'},
            { 'arxiv': 'https://arxiv.org/abs/2203.14478',
              'conf': 'CVPR 2022',
              'github': 'https://github.com/ZhengZerong/THUman4.0-Dataset',
              'title': 'Structured Local Radiance Fields for Human Avatar '
                       'Modeling',
              'website': 'http://www.liuyebin.com/slrf/slrf.html'},
            { 'arxiv': 'https://arxiv.org/abs/2203.14074',
              'conf': None,
              'github': None,
              'title': 'V3GAN: Decomposing Background, Foreground and Motion '
                       'for Video Generation',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2203.12848',
              'conf': None,
              'github': 'https://github.com/LexaNagiBator228/Keypoints-Tracking-via-Transformer-Networks',
              'title': 'Keypoints Tracking via Transformer Networks',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2203.12602',
              'conf': 'NeurIPS 2022',
              'github': 'https://github.com/MCG-NJU/VideoMAE',
              'title': 'VideoMAE: Masked Autoencoders are Data-Efficient '
                       'Learners for Self-Supervised Video Pre-Training',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2203.12178',
              'conf': 'CVPR 2022',
              'github': 'https://github.com/XiangZ-0/EVDI',
              'title': 'Unifying Motion Deblurring and Frame Interpolation '
                       'with Events',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2203.11632',
              'conf': None,
              'github': None,
              'title': 'QS-Craft: Learning to Quantize, Scrabble and Craft for '
                       'Conditional Human Motion Animation',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2203.10821',
              'conf': 'ECCV 2022',
              'github': 'https://github.com/donydchen/sem2nerf',
              'title': 'Sem2NeRF: Converting Single-View Semantic Masks to '
                       'Neural Radiance Fields',
              'website': 'https://donydchen.github.io/sem2nerf/'},
            { 'arxiv': 'https://arxiv.org/abs/2203.10528',
              'conf': 'TPAMI',
              'github': None,
              'title': 'Stochastic Video Prediction with Structure and Motion',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2203.10291',
              'conf': None,
              'github': None,
              'title': 'Exploring Motion Ambiguity and Alignment for '
                       'High-Quality Video Frame Interpolation',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2203.09771',
              'conf': None,
              'github': 'https://github.com/yangxy/SDL',
              'title': 'Beyond a Video Frame Interpolator: A Space Decoupled '
                       'Learning Approach to Continuous Image Transition',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2203.09494',
              'conf': None,
              'github': 'https://github.com/lucidrains/transframer-pytorch',
              'title': 'Transframer: Arbitrary Frame Prediction with '
                       'Generative Models',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2203.09457',
              'conf': 'CVPR 2022',
              'github': 'https://github.com/xrenaa/Look-Outside-Room',
              'title': 'Look Outside the Room: Synthesizing A Consistent '
                       'Long-Term 3D Scene Video from A Single Image',
              'website': 'https://xrenaa.github.io/look-outside-room/'},
            { 'arxiv': 'https://arxiv.org/abs/2203.09303',
              'conf': None,
              'github': 'https://github.com/AIS-Bonn/MSPred',
              'title': 'MSPred: Video Prediction at Multiple Spatio-Temporal '
                       'Scales with Hierarchical Recurrent Networks',
              'website': 'https://sites.google.com/view/mspred/home'},
            { 'arxiv': 'https://arxiv.org/abs/2203.09043',
              'conf': 'ICLR 2022',
              'github': 'https://github.com/wyhsirius/LIA',
              'title': 'Latent Image Animator: Learning to Animate Images via '
                       'Latent Space Navigation',
              'website': 'https://wyhsirius.github.io/LIA-project/'},
            { 'arxiv': 'https://arxiv.org/abs/2203.07931',
              'conf': None,
              'github': None,
              'title': 'DialogueNeRF: Towards Realistic Avatar Face-to-face '
                       'Conversation Video Generation',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2203.06421',
              'conf': None,
              'github': None,
              'title': 'One-stage Video Instance Segmentation: From Frame-in '
                       'Frame-out to Clip-in Clip-out',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2203.05189',
              'conf': None,
              'github': 'https://github.com/wyhuai/NeRFocus',
              'title': 'NeRFocus: Neural Radiance Field for 3D Synthetic '
                       'Defocus',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2203.02723',
              'conf': None,
              'github': None,
              'title': 'A Novel Dual Dense Connection Network for Video '
                       'Super-resolution',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2203.01978',
              'conf': 'BMVC 2022',
              'github': None,
              'title': 'Region-of-Interest Based Neural Video Compression',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2202.10758v1',
              'conf': 'ICIP 2022',
              'github': None,
              'title': 'Thinking the Fusion Strategy of Multi-reference Face '
                       'Reenactment',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2202.08418',
              'conf': 'AAAI 2022',
              'github': 'https://github.com/jinseokbae/neural_marionette',
              'title': 'Neural Marionette: Unsupervised Learning of Motion '
                       'Skeleton and Latent Dynamics from Volumetric Video',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2202.07731',
              'conf': None,
              'github': 'https://github.com/danier97/EDC',
              'title': 'Enhancing Deformable Convolution based Video Frame '
                       'Interpolation with Coarse-to-fine 3D CNN',
              'website': 'https://danier97.github.io/EDC/'},
            { 'arxiv': 'https://arxiv.org/abs/2202.07291',
              'conf': 'CVPR 2023',
              'github': 'https://github.com/pandatimo/Exploring-Discontinuity-for-VFI',
              'title': 'Exploring Discontinuity for Video Frame Interpolation',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2202.03046v1',
              'conf': None,
              'github': None,
              'title': 'A new face swap method for image and video domains: a '
                       'technical report',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2202.02183',
              'conf': None,
              'github': 'https://github.com/InterDigitalInc/FeatureStyleEncoder',
              'title': 'Feature-Style Encoder for Style-Based GAN Inversion',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2201.13433',
              'conf': None,
              'github': 'https://github.com/yuval-alaluf/stylegan3-editing',
              'title': "Third Time's the Charm? Image and Video Editing with "
                       'StyleGAN3',
              'website': 'https://yuval-alaluf.github.io/stylegan3-editing/'},
            { 'arxiv': 'https://arxiv.org/abs/2201.11632',
              'conf': 'TPAMI 2021',
              'github': 'https://github.com/ChenyangLEI/deep-video-prior',
              'title': 'Deep Video Prior for Video Consistency and Propagation',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2201.11407',
              'conf': 'CLIC, CVPR 2022',
              'github': 'https://github.com/saikatdutta/NME-VFI',
              'title': 'Non-linear Motion Estimation for Video Frame '
                       'Interpolation using Space-time Convolutions',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2201.10075',
              'conf': 'WACV 2023',
              'github': None,
              'title': 'Splatting-based Synthesis for Video Frame '
                       'Interpolation',
              'website': 'http://sniklaus.com/splatsyn'},
            { 'arxiv': 'https://arxiv.org/abs/2201.08361',
              'conf': None,
              'github': 'https://github.com/rotemtzaban/STIT',
              'title': 'Stitch it in Time: GAN-Based Facial Editing of Real '
                       'Videos',
              'website': 'https://stitch-time.github.io/'},
            { 'arxiv': 'https://arxiv.org/abs/2201.07422',
              'conf': None,
              'github': 'https://github.com/csbhr/Self-Blind-VSR',
              'title': 'Self-Supervised Deep Blind Video Super-Resolution',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2201.06888',
              'conf': None,
              'github': None,
              'title': 'Autoencoding Video Latents for Adversarial Video '
                       'Generation',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2201.06494',
              'conf': None,
              'github': 'https://github.com/facebookresearch/AugLy',
              'title': 'AugLy: Data Augmentations for Robustness',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2201.06260',
              'conf': 'ACMMM 2021',
              'github': None,
              'title': 'Towards Realistic Visual Dubbing with Heterogeneous '
                       'Sources',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2201.05986',
              'conf': 'IEEE',
              'github': None,
              'title': 'Audio-Driven Talking Face Video Generation with '
                       'Dynamic Convolution Kernels',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2201.05723',
              'conf': 'AAAI 2022',
              'github': 'https://github.com/wangkaihong/Unsup_Recycle_GAN/',
              'title': 'Learning Temporally and Semantically Consistent '
                       'Unpaired Video-to-video Translation Through '
                       'Pseudo-Supervision From Synthetic Optical Flow',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2201.04851',
              'conf': None,
              'github': None,
              'title': 'MetaDance: Few-shot Dancing Video Retargeting via '
                       'Temporal-aware Meta-learning',
              'website': 'https://github.com/geyuying/MetaDance'},
            { 'arxiv': 'https://arxiv.org/abs/2201.03809',
              'conf': None,
              'github': 'https://github.com/joeljang/music2video',
              'title': 'Music2Video: Automatic Generation of Music Video with '
                       'fusion of audio and text',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2201.03808',
              'conf': 'AAAI 2022',
              'github': 'https://github.com/Seanseattle/MobileFaceSwap',
              'title': 'MobileFaceSwap: A Lightweight Framework for Video Face '
                       'Swapping',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2212.06820',
              'conf': 'CVPR 2023',
              'github': None,
              'title': 'Structured 3D Features for Reconstructing Controllable '
                       'Avatars',
              'website': 'https://enriccorona.github.io/s3f/'},
            { 'arxiv': 'https://arxiv.org/abs/2212.04495',
              'conf': 'CVPR 2023',
              'github': None,
              'title': 'MoFusion: A Framework for Denoising-Diffusion-based '
                       'Motion Synthesis',
              'website': 'https://vcai.mpi-inf.mpg.de/projects/MoFusion/'},
            { 'arxiv': 'https://arxiv.org/abs/2211.15064',
              'conf': None,
              'github': 'https://github.com/bbaaii/HFA-GP',
              'title': 'High-fidelity Facial Avatar Reconstruction from '
                       'Monocular Video with Generative Priors',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2211.14108',
              'conf': None,
              'github': None,
              'title': '3DDesigner: Towards Photorealistic 3D Object '
                       'Generation and Editing with Text-guided Diffusion '
                       'Models',
              'website': 'https://3ddesigner-diffusion.github.io/'},
            { 'arxiv': 'https://arxiv.org/abs/2211.10883',
              'conf': None,
              'github': None,
              'title': 'Audio-visual video face hallucination with frequency '
                       'supervision and cross modality support by speech based '
                       'lip reading loss',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2210.05234',
              'conf': None,
              'github': None,
              'title': 'It Takes Two: Masked Appearance-Motion Modeling for '
                       'Self-supervised Video Transformer Pre-training',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2210.03825',
              'conf': None,
              'github': None,
              'title': 'See, Plan, Predict: Language-guided Cognitive Planning '
                       'with Video Prediction',
              'website': 'https://see-pp.github.io/'},
            { 'arxiv': 'https://arxiv.org/abs/2209.14024',
              'conf': 'ECCV 2022',
              'github': 'https://github.com/JialeTao/MoTrans',
              'title': 'Motion Transformer for Unsupervised Image Animation',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2208.11014',
              'conf': None,
              'github': None,
              'title': 'Low-Light Video Enhancement with Synthetic Event '
                       'Guidance',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2208.08728',
              'conf': 'ECCV 2022',
              'github': None,
              'title': 'Neural Capture of Animatable 3D Human from Monocular '
                       'Video',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2207.09193',
              'conf': 'ECCV 2022',
              'github': 'https://github.com/HKBU-VSComputing/2022_ECCV_NDF',
              'title': 'NDF: Neural Deformable Fields for Dynamic Human '
                       'Modelling',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2207.05906',
              'conf': None,
              'github': 'https://github.com/godzillalla/Dance-Synthesis-Project',
              'title': 'Diverse Dance Synthesis via Keyframes with Transformer '
                       'Controllers',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2206.15248',
              'conf': None,
              'github': None,
              'title': 'CTrGAN: Cycle Transformers GAN for Gait Transfer',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2206.12657',
              'conf': None,
              'github': None,
              'title': 'Enhanced Deep Animation Video Interpolation',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2204.06862',
              'conf': None,
              'github': None,
              'title': 'An Identity-Preserved Framework for Human Motion '
                       'Transfer',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2204.00795',
              'conf': None,
              'github': None,
              'title': 'Unsupervised Coherent Video Cartoonization with '
                       'Perceptual Motion Consistency',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2202.11855',
              'conf': 'CoRL 2022',
              'github': None,
              'title': 'Learning Multi-Object Dynamics with Compositional '
                       'Neural Radiance Fields',
              'website': 'https://dannydriess.github.io/compnerfdyn/'},
            { 'arxiv': 'https://arxiv.org/abs/2201.12288',
              'conf': None,
              'github': 'https://github.com/JingyunLiang/VRT',
              'title': 'VRT: A Video Restoration Transformer',
              'website': None}],
  '2023': [ { 'arxiv': 'https://arxiv.org/abs/2307.09906',
              'conf': 'ICCV 2023',
              'github': 'https://github.com/harlanhong/iccv2023-mcnet',
              'title': 'Implicit Identity Representation Conditioned Memory '
                       'Compensation Network for Talking Head video Generation',
              'website': 'https://harlanhong.github.io/publications/mcnet.html'},
            { 'arxiv': 'https://arxiv.org/abs/2205.14135',
              'conf': None,
              'github': 'https://github.com/dao-ailab/flash-attention',
              'title': 'FlashAttention-2: Faster Attention with Better '
                       'Parallelism and Work Partitioning',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2307.07754',
              'conf': None,
              'github': 'https://github.com/rocketappslab/bdmm',
              'title': 'Bidirectionally Deformable Motion Modulation For '
                       'Video-based Human Pose Transfer',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2307.06940',
              'conf': None,
              'github': 'https://github.com/videocrafter/animate-a-story',
              'title': 'Animate-A-Story: Storytelling with Retrieval-Augmented '
                       'Video Generation',
              'website': 'https://videocrafter.github.io/Animate-A-Story/'},
            { 'arxiv': 'https://arxiv.org/abs/2306.11173',
              'conf': None,
              'github': 'https://github.com/lapid92/gd-vdm',
              'title': 'GD-VDM: Generated Depth for better Diffusion-based '
                       'Video Generation',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2306.05957',
              'conf': None,
              'github': 'https://github.com/taldatech/ddlp',
              'title': 'DDLP: Unsupervised Object-Centric Video Prediction '
                       'with Deep Dynamic Latent Particles',
              'website': 'https://taldatech.github.io/ddlp-web/'},
            { 'arxiv': 'https://arxiv.org/abs/2306.02562',
              'conf': 'IJCAI 2023',
              'github': 'https://github.com/exisas/lgc-vd',
              'title': 'Video Diffusion Models with Local-Global Context '
                       'Guidance',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2305.18264',
              'conf': None,
              'github': 'https://github.com/g-u-n/gen-l-video',
              'title': 'Gen-L-Video: Multi-Text to Long Video Generation via '
                       'Temporal Co-Denoising',
              'website': 'https://g-u-n.github.io/projects/gen-long-video/index.html'},
            { 'arxiv': 'https://arxiv.org/abs/2305.14330',
              'conf': None,
              'github': 'https://github.com/ku-cvlab/direct2v',
              'title': 'Large Language Models are Frame-level Directors for '
                       'Zero-shot Text-to-Video Generation',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2306.01872',
              'conf': None,
              'github': None,
              'title': 'Probabilistic Adaptation of Text-to-Video Models',
              'website': 'https://video-adapter.github.io/video-adapter/'},
            { 'arxiv': 'https://arxiv.org/abs/2212.00235',
              'conf': 'AAAI 2023',
              'github': 'https://github.com/MKFMIKU/VIDM',
              'title': 'VIDM: Video Implicit Diffusion Models',
              'website': 'https://kfmei.page/vidm/'},
            { 'arxiv': 'https://arxiv.org/abs/2212.09478',
              'conf': 'CVPR 2023',
              'github': 'https://github.com/researchmm/MM-Diffusion',
              'title': 'Mm-Diffusion: Learning Multi-Modal Diffusion Models '
                       'for Joint Audio and Video Generation',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2302.07685',
              'conf': 'CVPR 2023',
              'github': 'https://github.com/sihyun-yu/PVDM',
              'title': 'Video Probabilistic Diffusion Models in Projected '
                       'Latent Space',
              'website': 'https://sihyun.me/PVDM/'},
            { 'arxiv': 'https://arxiv.org/abs/2307.03190',
              'conf': None,
              'github': 'https://github.com/text2cinemagraph/text2cinemagraph',
              'title': 'Synthesizing Artistic Cinemagraphs from Text',
              'website': 'https://text2cinemagraph.github.io/website/'},
            { 'arxiv': 'https://arxiv.org/abs/2307.00574',
              'conf': None,
              'github': None,
              'title': 'Bidirectional Temporal Diffusion Model for Temporally '
                       'Consistent Human Animation',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2307.00040',
              'conf': None,
              'github': 'https://github.com/Wangt-CN/DisCo',
              'title': 'DisCo: Disentangled Control for Referring Human Dance '
                       'Generation in Real World',
              'website': 'https://disco-dance.github.io/'},
            { 'arxiv': 'https://arxiv.org/abs/2306.17123',
              'conf': None,
              'github': 'https://github.com/ken2576/pvp',
              'title': 'PVP: Personalized Video Prior for Editable Dynamic '
                       'Portraits using StyleGAN',
              'website': 'https://cseweb.ucsd.edu//~viscomp/projects/EGSR23PVP/'},
            { 'arxiv': 'https://arxiv.org/abs/2306.16940',
              'conf': 'CVPR 2023',
              'github': 'https://github.com/pixelite1201/BEDLAM',
              'title': 'BEDLAM: A Synthetic Dataset of Bodies Exhibiting '
                       'Detailed Lifelike Animated Motion',
              'website': 'https://bedlam.is.tue.mpg.de/'},
            { 'arxiv': 'https://arxiv.org/abs/2306.16541',
              'conf': 'CVPR 2023',
              'github': None,
              'title': 'Envisioning a Next Generation Extended Reality '
                       'Conferencing System with Efficient Photorealistic '
                       'Human Rendering',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2306.16003',
              'conf': None,
              'github': None,
              'title': 'Reprogramming Audio-driven Talking Face Synthesis into '
                       'Text-driven',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2306.15507',
              'conf': None,
              'github': None,
              'title': 'Self-supervised Learning of Event-guided Video Frame '
                       'Interpolation for Rolling Shutter Frames',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2306.13933',
              'conf': None,
              'github': None,
              'title': 'Boost Video Frame Interpolation via Motion Adaptation',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2306.08707',
              'conf': None,
              'github': None,
              'title': 'VidEdit: Zero-Shot and Spatially Aware Text-Driven '
                       'Video Editing',
              'website': 'https://videdit.github.io/'},
            { 'arxiv': 'https://arxiv.org/abs/2306.08068',
              'conf': None,
              'github': None,
              'title': 'DORSal: Diffusion for Object-centric Representations '
                       'of Scenes',
              'website': 'https://www.sjoerdvansteenkiste.com/dorsal/'},
            { 'arxiv': 'https://arxiv.org/abs/2306.07954',
              'conf': None,
              'github': None,
              'title': 'Rerender A Video: Zero-Shot Text-Guided Video-to-Video '
                       'Translation',
              'website': 'https://anonymous-31415926.github.io/'},
            { 'arxiv': 'https://arxiv.org/abs/2306.04321',
              'conf': None,
              'github': None,
              'title': 'Generative Semantic Communication: Diffusion Models '
                       'Beyond Bit Recovery',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2306.02903',
              'conf': None,
              'github': 'https://github.com/lsx0101/Instruct-Video2Avatar',
              'title': 'Instruct-Video2Avatar: Video-to-Avatar Generation with '
                       'Instructions',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2306.02252',
              'conf': None,
              'github': None,
              'title': 'MoviePuzzle: Visual Narrative Reasoning through '
                       'Multimodal Order Learning',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2306.01732',
              'conf': None,
              'github': None,
              'title': 'Video Colorization with Pre-trained Text-to-Image '
                       'Diffusion Models',
              'website': 'https://colordiffuser.github.io/'},
            { 'arxiv': 'https://arxiv.org/abs/2306.01704',
              'conf': None,
              'github': 'https://github.com/ostadabbas/Temporal-controlled-Frame-Swap-GTAV-TeFS-',
              'title': 'Temporal-controlled Frame Swap for Generating '
                       'High-Fidelity Stereo Driving Data for Autonomy '
                       'Analysis',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2306.01344',
              'conf': None,
              'github': None,
              'title': 'Adjustable Visual Appearance for Generalizable Novel '
                       'View Synthesis',
              'website': 'https://ava-nvs.github.io/'},
            { 'arxiv': 'https://arxiv.org/abs/2306.01081',
              'conf': None,
              'github': None,
              'title': '4DSR-GCN: 4D Video Point Cloud Upsampling using Graph '
                       'Convolutional Networks',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2306.00973',
              'conf': None,
              'github': None,
              'title': 'Intelligent Grimm -- Open-ended Visual Storytelling '
                       'via Latent Diffusion Models',
              'website': 'https://haoningwu3639.github.io/StoryGen_Webpage/'},
            { 'arxiv': 'https://arxiv.org/abs/2306.00576',
              'conf': None,
              'github': None,
              'title': 'MammalNet: A Large-scale Video Benchmark for Mammal '
                       'Recognition and Behavior Understanding',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2305.19556',
              'conf': None,
              'github': None,
              'title': 'Exploring Phonetic Context in Lip Movement for '
                       'Authentic Talking Face Generation',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2305.19193',
              'conf': None,
              'github': None,
              'title': 'Video ControlNet: Towards Temporally Consistent '
                       'Synthetic-to-Real Video Translation Using Conditional '
                       'Image Diffusion Models',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2305.19135',
              'conf': None,
              'github': None,
              'title': 'Context-Preserving Two-Stage Video Domain Translation '
                       'for Portrait Stylization',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2305.14831',
              'conf': None,
              'github': None,
              'title': 'OD-NeRF: Efficient Training of On-the-Fly Dynamic '
                       'Neural Radiance Fields',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2305.14708',
              'conf': None,
              'github': None,
              'title': 'EgoVSR: Towards High-Quality Egocentric Video '
                       'Super-Resolution',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2305.14669',
              'conf': None,
              'github': None,
              'title': 'NegVSR: Augmenting Negatives for Generalized Noise '
                       'Modeling in Real-World Video Super-Resolution',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2305.14343',
              'conf': None,
              'github': None,
              'title': 'Video Prediction Models as Rewards for Reinforcement '
                       'Learning',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2305.14135',
              'conf': None,
              'github': None,
              'title': 'Reparo: Loss-Resilient Generative Codec for Video '
                       'Conferencing',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2305.13962',
              'conf': 'ICME 2023',
              'github': None,
              'title': 'CPNet: Exploiting CLIP-based Attention Condenser and '
                       'Probability Map Guidance for High-fidelity Talking '
                       'Face Generation',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2305.12411',
              'conf': None,
              'github': None,
              'title': 'Synthesizing Diverse Human Motions in 3D Indoor Scenes',
              'website': 'https://zkf1997.github.io/DIMOS/'},
            { 'arxiv': 'https://arxiv.org/abs/2305.12328',
              'conf': None,
              'github': None,
              'title': 'InstructVid2Vid: Controllable Video Editing with '
                       'Natural Language Instructions',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2305.11281',
              'conf': 'ICLR Workshop 2023',
              'github': None,
              'title': 'SlotDiffusion: Object-Centric Generative Modeling with '
                       'Diffusion Models',
              'website': 'https://slotdiffusion.github.io/'},
            { 'arxiv': 'https://arxiv.org/abs/2305.10198',
              'conf': None,
              'github': None,
              'title': 'IDO-VFI: Identifying Dynamics via Optical Flow '
                       'Guidance for Video Frame Interpolation with Events',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2305.09512',
              'conf': None,
              'github': None,
              'title': 'Light-VQA: A Multi-Dimensional Quality Assessment '
                       'Model for Low-Light Video Enhancement',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2305.08854',
              'conf': None,
              'github': None,
              'title': 'Laughing Matters: Introducing Laughing-Face Generation '
                       'using Diffusion Models',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2305.08293',
              'conf': 'CVPR 2023',
              'github': 'https://github.com/Weizhi-Zhong/IP_LAP',
              'title': 'Identity-Preserving Talking Face Generation with '
                       'Landmark and Appearance Priors',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2305.06356',
              'conf': None,
              'github': 'https://github.com/synthesiaresearch/humanrf',
              'title': 'HumanRF: High-Fidelity Neural Radiance Fields for '
                       'Humans in Motion',
              'website': 'https://synthesiaresearch.github.io/humanrf/'},
            { 'arxiv': 'https://arxiv.org/abs/2305.05464',
              'conf': None,
              'github': 'https://github.com/haha-lisa/Style-A-Video',
              'title': 'Style-A-Video: Agile Diffusion for Arbitrary '
                       'Text-based Video Style Transfer',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2305.03049',
              'conf': 'CVPR 2023',
              'github': None,
              'title': 'NeuralEditor: Editing Neural Radiance Fields via '
                       'Manipulating Point Clouds',
              'website': 'https://immortalco.github.io/NeuralEditor/'},
            { 'arxiv': 'https://arxiv.org/abs/2305.00126',
              'conf': None,
              'github': 'https://github.com/ZZY-Zhou/DSEC-MOS',
              'title': 'DSEC-MOS: Segment Any Moving Object with Moving Ego '
                       'Vehicle',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2304.13596',
              'conf': 'IJCAI 2023',
              'github': 'https://github.com/kinoud/DQBC',
              'title': 'Video Frame Interpolation with Densely Queried '
                       'Bilateral Correlation',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2304.12664',
              'conf': None,
              'github': None,
              'title': 'Dynamic Video Frame Interpolation with integrated '
                       'Difficulty Pre-Assessment',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2304.09790',
              'conf': 'CVPR 2023',
              'github': 'https://github.com/MCG-NKU/AMT',
              'title': 'AMT: All-Pairs Multi-Field Transforms for Efficient '
                       'Frame Interpolation',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2304.08477',
              'conf': None,
              'github': None,
              'title': 'Latent-Shift: Latent Diffusion with Temporal Shift for '
                       'Efficient Text-to-Video Generation',
              'website': 'https://latent-shift.github.io/'},
            { 'arxiv': 'https://arxiv.org/abs/2304.07915',
              'conf': 'CVPR Workshop 2023',
              'github': None,
              'title': 'CAT-NeRF: Constancy-Aware Tx$^2$Former for Dynamic '
                       'Body Modeling',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2304.06818',
              'conf': None,
              'github': None,
              'title': 'Soundini: Sound-Guided Diffusion for Natural Video '
                       'Editing',
              'website': 'https://kuai-lab.github.io/soundini-gallery/'},
            { 'arxiv': 'https://arxiv.org/abs/2304.06211',
              'conf': 'CVPR 2023',
              'github': 'https://github.com/wenguanwang/VOS_Correspondence',
              'title': 'Boosting Video Object Segmentation via Space-time '
                       'Correspondence Learning',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2304.06020',
              'conf': None,
              'github': None,
              'title': 'VidStyleODE: Disentangled Video Editing via StyleGAN '
                       'and NeuralODEs',
              'website': 'https://cyberiada.github.io/VidStyleODE/'},
            { 'arxiv': 'https://arxiv.org/abs/2304.05930',
              'conf': 'CVPR 2023',
              'github': 'https://github.com/rkyuca/medvt',
              'title': 'MED-VT: Multiscale Encoder-Decoder Video Transformer '
                       'with Application to Object Segmentation',
              'website': 'https://rkyuca.github.io/medvt/'},
            { 'arxiv': 'https://arxiv.org/abs/2304.04897',
              'conf': None,
              'github': None,
              'title': 'Neural Image-based Avatars: Generalizable Radiance '
                       'Fields for Human Avatar Modeling',
              'website': 'https://youngjoongunc.github.io/nia/'},
            { 'arxiv': 'https://arxiv.org/abs/2304.03275',
              'conf': None,
              'github': None,
              'title': "That's What I Said: Fully-Controllable Talking Face "
                       'Generation',
              'website': 'https://mm.kaist.ac.kr/projects/FC-TFG/'},
            { 'arxiv': 'https://arxiv.org/abs/2304.02633',
              'conf': 'CVPR 2023',
              'github': 'https://github.com/haochen-rye/HNeRV',
              'title': 'HNeRV: A Hybrid Neural Representation for Videos',
              'website': 'https://haochen-rye.github.io/HNeRV/'},
            { 'arxiv': 'https://arxiv.org/abs/2304.02225',
              'conf': 'CVPR 2023',
              'github': 'https://github.com/JunHeum/BiFormer',
              'title': 'BiFormer: Learning Bilateral Motion Estimation via '
                       'Bilateral Transformer for 4K Video Frame Interpolation',
              'website': 'https://openaccess.thecvf.com/content/CVPR2023/papers/Park_BiFormer_Learning_Bilateral_Motion_Estimation_via_Bilateral_Transformer_for_4K_CVPR_2023_paper.pdf'},
            { 'arxiv': 'https://arxiv.org/abs/2304.00334',
              'conf': None,
              'github': None,
              'title': 'TalkCLIP: Talking Head Generation with Text-Guided '
                       'Expressive Speaking Styles',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2303.17789',
              'conf': 'ICME 2023',
              'github': None,
              'title': 'FONT: Flow-guided One-shot Talking Head Generation '
                       'with Natural Head Motions',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2303.17599',
              'conf': None,
              'github': 'https://github.com/baaivision/vid2vid-zero',
              'title': 'Zero-Shot Video Editing Using Off-The-Shelf Image '
                       'Diffusion Models',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2303.17598',
              'conf': 'CVPR 2023',
              'github': None,
              'title': 'Consistent View Synthesis with Pose-Guided Diffusion '
                       'Models',
              'website': 'https://poseguided-diffusion.github.io/'},
            { 'arxiv': 'https://arxiv.org/abs/2303.17550',
              'conf': None,
              'github': None,
              'title': 'DAE-Talker: High Fidelity Speech-Driven Talking Face '
                       'Generation with Diffusion Autoencoder',
              'website': 'https://daetalker.github.io/'},
            { 'arxiv': 'https://arxiv.org/abs/2303.15880',
              'conf': None,
              'github': None,
              'title': 'Novel View Synthesis of Humans using Differentiable '
                       'Rendering',
              'website': 'https://github.com/GuillaumeRochette/HumanViewSynthesis'},
            { 'arxiv': 'https://arxiv.org/abs/2303.14717',
              'conf': 'CVPR 2023',
              'github': 'https://github.com/celebv-text/CelebV-Text',
              'title': 'CelebV-Text: A Large-Scale Facial Text-Video Dataset',
              'website': 'https://celebv-text.github.io/'},
            { 'arxiv': 'https://arxiv.org/abs/2303.14613',
              'conf': 'SIGGRAPH 2023',
              'github': None,
              'title': 'GestureDiffuCLIP: Gesture Diffusion Model with CLIP '
                       'Latents',
              'website': 'https://pku-mocca.github.io/GestureDiffuCLIP-Page/'},
            { 'arxiv': 'https://arxiv.org/abs/2303.14536',
              'conf': 'CVPR 2023',
              'github': 'https://github.com/hturki/suds',
              'title': 'SUDS: Scalable Urban Dynamic Scenes',
              'website': 'https://haithemturki.com/suds/'},
            { 'arxiv': 'https://arxiv.org/abs/2303.14435',
              'conf': 'CVPR 2023',
              'github': 'https://github.com/JokerYan/NeRF-DS',
              'title': 'NeRF-DS: Neural Radiance Fields for Dynamic Specular '
                       'Objects',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2303.13825',
              'conf': 'CVPR 2023',
              'github': None,
              'title': 'HandNeRF: Neural Radiance Fields for Animatable '
                       'Interacting Hands',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2303.13439',
              'conf': None,
              'github': 'https://github.com/Picsart-AI-Research/Text2Video-Zero',
              'title': 'Text2Video-Zero: Text-to-Image Diffusion Models are '
                       'Zero-Shot Video Generators',
              'website': 'https://text2video-zero.github.io/'},
            { 'arxiv': 'https://arxiv.org/abs/2303.12791',
              'conf': None,
              'github': 'https://github.com/skhu101/SHERF',
              'title': 'SHERF: Generalizable Human NeRF from a Single Image',
              'website': 'https://skhu101.github.io/SHERF/'},
            { 'arxiv': 'https://arxiv.org/abs/2303.12688',
              'conf': None,
              'github': 'https://github.com/G-U-N/Pix2Video.pytorch',
              'title': 'Pix2Video: Video Editing using Image Diffusion',
              'website': 'https://duyguceylan.github.io/pix2video.github.io/'},
            { 'arxiv': 'https://arxiv.org/abs/2303.12337',
              'conf': 'CVPR 2023',
              'github': 'https://github.com/aioz-ai/AIOZ-GDANCE',
              'title': 'Music-Driven Group Choreography',
              'website': 'https://aioz-ai.github.io/AIOZ-GDANCE/'},
            { 'arxiv': 'https://arxiv.org/abs/2303.12234',
              'conf': None,
              'github': 'https://github.com/CVUBLab/pre-nerf',
              'title': 'Pre-NeRF 360: Enriching Unbounded Appearances for '
                       'Neural Radiance Fields',
              'website': 'https://amughrabi.github.io/prenerf/'},
            { 'arxiv': 'https://arxiv.org/abs/2303.11548',
              'conf': None,
              'github': 'https://github.com/sahilg06/EmoGen',
              'title': 'Emotionally Enhanced Talking Face Generation',
              'website': 'https://midas.iiitd.edu.in/emo/'},
            { 'arxiv': 'https://arxiv.org/abs/2303.11003',
              'conf': None,
              'github': None,
              'title': 'Tubelet-Contrastive Self-Supervision for '
                       'Video-Efficient Generalization',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2303.10452',
              'conf': None,
              'github': None,
              'title': 'Confidence Attention and Generalization Enhanced '
                       'Distillation for Continuous Video Domain Adaptation',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2303.10275',
              'conf': None,
              'github': None,
              'title': 'MoRF: Mobile Realistic Fullbody Avatars from a '
                       'Monocular Video',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2303.10100',
              'conf': None,
              'github': None,
              'title': 'Unified Mask Embedding and Correspondence Learning for '
                       'Self-Supervised Video Segmentation',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2303.09941',
              'conf': None,
              'github': None,
              'title': 'Leaping Into Memories: Space-Time Deep Feature '
                       'Synthesis',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2303.09826',
              'conf': None,
              'github': None,
              'title': 'Learning Data-Driven Vector-Quantized Degradation '
                       'Model for Animation Video Super-Resolution',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2303.09535',
              'conf': None,
              'github': 'https://github.com/ChenyangQiQi/FateZero',
              'title': 'FateZero: Fusing Attentions for Zero-shot Text-based '
                       'Video Editing',
              'website': 'https://fate-zero-edit.github.io/'},
            { 'arxiv': 'https://arxiv.org/abs/2303.09508',
              'conf': None,
              'github': None,
              'title': 'LDMVFI: Video Frame Interpolation with Latent '
                       'Diffusion Models',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2303.09370',
              'conf': None,
              'github': None,
              'title': 'Learning Physical-Spatio-Temporal Features for Video '
                       'Shadow Removal',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2303.09170',
              'conf': None,
              'github': 'https://github.com/semchan/NLUT',
              'title': 'NLUT: Neural-based 3D Lookup Tables for Video '
                       'Photorealistic Style Transfer',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2303.08639',
              'conf': 'CVPR 2023',
              'github': 'https://hbertiche.github.io/CycleNet/',
              'title': 'Blowing in the Wind: CycleNet for Human Cinemagraphs '
                       'from Still Images',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2303.08120',
              'conf': 'CVPR 2023',
              'github': 'https://github.com/ChenyangLEI/All-In-One-Deflicker',
              'title': 'Blind Video Deflickering by Neural Filtering with a '
                       'Flawed Atlas',
              'website': 'https://chenyanglei.github.io/deflicker/'},
            { 'arxiv': 'https://arxiv.org/abs/2303.02959',
              'conf': 'DCC 2023',
              'github': None,
              'title': 'Butterfly: Multiple Reference Frames Feature '
                       'Propagation Mechanism for Neural Video Compression',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2302.14362',
              'conf': 'AAAI 2023',
              'github': None,
              'title': 'One-Shot Video Inpainting',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2302.13256',
              'conf': None,
              'github': None,
              'title': 'Continuous Space-Time Video Super-Resolution Utilizing '
                       'Long-Range Temporal Information',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2302.12237',
              'conf': 'CVPR 2023',
              'github': 'https://github.com/zju3dv/instant-nvr',
              'title': 'Learning Neural Volumetric Representations of Dynamic '
                       'Humans in Minutes',
              'website': 'https://zju3dv.github.io/instant_nvr/'},
            { 'arxiv': 'https://arxiv.org/abs/2302.10001',
              'conf': None,
              'github': 'https://github.com/RLado/STB-VMM',
              'title': 'STB-VMM: Swin Transformer Based Video Motion '
                       'Magnification',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2302.08197',
              'conf': 'ICASSP 2023',
              'github': None,
              'title': 'OPT: One-shot Pose-Controllable Talking Head '
                       'Generation',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2302.07848',
              'conf': None,
              'github': None,
              'title': 'One-Shot Face Video Re-enactment using Hybrid Latent '
                       'Spaces of StyleGAN2',
              'website': 'https://trevineoorloff.github.io/FaceVideoReenactment_HybridLatents.io/'},
            { 'arxiv': 'https://arxiv.org/abs/2302.05916',
              'conf': None,
              'github': 'https://github.com/csqiangwen/Video_Waterdrop_Removal_in_Driving_Scenes',
              'title': 'Video Waterdrop Removal via Spatio-Temporal Fusion in '
                       'Driving Scenes',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2302.03011',
              'conf': None,
              'github': None,
              'title': 'Structure and Content-Guided Video Synthesis with '
                       'Diffusion Models',
              'website': 'https://research.runwayml.com/gen1'},
            { 'arxiv': 'https://arxiv.org/abs/2302.02088',
              'conf': None,
              'github': None,
              'title': 'AV-NeRF: Learning Neural Fields for Real-World '
                       'Audio-Visual Scene Synthesis',
              'website': 'https://liangsusan-git.github.io/project/avnerf/'},
            { 'arxiv': 'https://arxiv.org/abs/2302.01329',
              'conf': None,
              'github': None,
              'title': 'Dreamix: Video Diffusion Models are General Video '
                       'Editors',
              'website': 'https://dreamix-video-editing.github.io/'},
            { 'arxiv': 'https://arxiv.org/abs/2302.01133',
              'conf': None,
              'github': 'https://github.com/RafailFridman/SceneScape',
              'title': 'SceneScape: Text-Driven Consistent Scene Generation',
              'website': 'https://scenescape.github.io/'},
            { 'arxiv': 'https://arxiv.org/abs/2301.12352',
              'conf': None,
              'github': None,
              'title': 'Maximal Cliques on Multi-Frame Proposal Graph for '
                       'Unsupervised Video Object Segmentation',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2301.11880',
              'conf': None,
              'github': None,
              'title': 'Optical Flow Estimation in 360$^\\circ$ Videos: '
                       'Dataset, Model and Application',
              'website': 'https://siamlof.github.io/'},
            { 'arxiv': 'https://arxiv.org/abs/2301.11326',
              'conf': None,
              'github': None,
              'title': 'Unsupervised Volumetric Animation',
              'website': 'https://snap-research.github.io/unsupervised-volumetric-animation/'},
            { 'arxiv': 'https://arxiv.org/abs/2301.11280',
              'conf': None,
              'github': None,
              'title': 'Text-To-4D Dynamic Scene Generation',
              'website': 'https://make-a-video3d.github.io/'},
            { 'arxiv': 'https://arxiv.org/abs/2301.08846',
              'conf': None,
              'github': None,
              'title': 'Regeneration Learning: A Learning Paradigm for Data '
                       'Generation',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2301.05191',
              'conf': 'CVPR 2023',
              'github': 'https://github.com/AHupuJR/REFID',
              'title': 'Event-Based Frame Interpolation with Ad-hoc Deblurring',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2301.03786',
              'conf': 'CVPR 2023',
              'github': None,
              'title': 'DiffTalk: Crafting Diffusion Models for Generalized '
                       'Audio-Driven Portraits Animation',
              'website': 'https://sstzal.github.io/DiffTalk/'},
            { 'arxiv': 'https://arxiv.org/abs/2301.03396',
              'conf': None,
              'github': None,
              'title': 'Diffused Heads: Diffusion Models Beat GANs on '
                       'Talking-Face Generation',
              'website': 'https://mstypulkowski.github.io/diffusedheads/'},
            { 'arxiv': 'https://arxiv.org/abs/2301.02238',
              'conf': 'CVPR 2023',
              'github': 'https://github.com/facebookresearch/hyperreel',
              'title': 'HyperReel: High-Fidelity 6-DoF Video with '
                       'Ray-Conditioned Sampling',
              'website': 'https://hyperreel.github.io/'},
            { 'arxiv': 'https://arxiv.org/abs/2301.01081',
              'conf': 'AAAI 2023',
              'github': None,
              'title': 'StyleTalk: One-shot Talking Head Generation with '
                       'Controllable Speaking Styles',
              'website': 'https://github.com/FuxiVirtualHuman/styletalk'},
            { 'arxiv': 'https://arxiv.org/abs/2301.00411',
              'conf': None,
              'github': 'https://github.com/Luciferbobo/D4NeRF',
              'title': 'Detachable Novel Views Synthesis of Dynamic Scenes '
                       'Using Distribution-Driven Neural Radiance Fields',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2306.11682',
              'conf': None,
              'github': None,
              'title': 'SkyGPT: Probabilistic Short-term Solar Forecasting '
                       'Using Synthetic Sky Videos from Physics-constrained '
                       'VideoGPT',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2306.07257',
              'conf': None,
              'github': None,
              'title': 'MovieFactory: Automatic Movie Creation from Text using '
                       'Large Generative Models for Language and Images',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2306.03594',
              'conf': None,
              'github': None,
              'title': 'Emotional Talking Head Generation based on '
                       'Memory-Sharing and Attention-Augmented Networks',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2305.11772',
              'conf': None,
              'github': None,
              'title': 'Neural Foundations of Mental Simulation: Future '
                       'Prediction of Latent Representations on Dynamic Scenes',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2305.03713',
              'conf': None,
              'github': None,
              'title': 'Avatar Fingerprinting for Authorized Use of Synthetic '
                       'Talking-Head Videos',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2305.02296',
              'conf': 'CVPR 2023',
              'github': 'https://github.com/facebookresearch/dynamic_stereo',
              'title': 'DynamicStereo: Consistent Dynamic Depth from Stereo '
                       'Videos',
              'website': 'https://dynamic-stereo.github.io/'},
            { 'arxiv': 'https://arxiv.org/abs/2304.14401',
              'conf': None,
              'github': None,
              'title': 'ActorsNeRF: Animatable Few-shot Human Rendering with '
                       'Generalizable NeRFs',
              'website': 'https://jitengmu.github.io/ActorsNeRF/'},
            { 'arxiv': 'https://arxiv.org/abs/2304.12317',
              'conf': None,
              'github': 'https://github.com/andrewsonga/Total-Recon',
              'title': 'Total-Recon: Deformable Scene Reconstruction for '
                       'Embodied View Synthesis',
              'website': 'https://andrewsonga.github.io/totalrecon/'},
            { 'arxiv': 'https://arxiv.org/abs/2304.11470',
              'conf': 'CVPR 2023',
              'github': None,
              'title': '3D-IntPhys: Towards More Generalized 3D-grounded '
                       'Visual Intuitive Physics under Challenging Scenes',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2304.06403',
              'conf': 'CVPR 2023',
              'github': None,
              'title': 'Leveraging triplet loss for unsupervised action '
                       'segmentation',
              'website': 'https://github.com/elenabbbuenob/tsa-actionseg'},
            { 'arxiv': 'https://arxiv.org/abs/2304.02001',
              'conf': 'CVPR 2023',
              'github': None,
              'title': 'MonoHuman: Animatable Human Neural Field from '
                       'Monocular Video',
              'website': 'https://yzmblog.github.io/projects/MonoHuman/'},
            { 'arxiv': 'https://arxiv.org/abs/2304.01893',
              'conf': 'CVPR 2023',
              'github': None,
              'title': 'Trace and Pace: Controllable Pedestrian Animation via '
                       'Guided Trajectory Diffusion',
              'website': 'https://research.nvidia.com/labs/toronto-ai/trace-pace/'},
            { 'arxiv': 'https://arxiv.org/abs/2303.17480',
              'conf': 'CVPR 2023',
              'github': 'https://github.com/Sxjdwang/TalkLip',
              'title': 'Seeing What You Said: Talking Face Generation Guided '
                       'by a Lip Reading Expert',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2303.15893',
              'conf': 'CVPR 2023',
              'github': None,
              'title': 'VIVE3D: Viewpoint-Independent Video Editing using '
                       '3D-Aware GANs',
              'website': 'http://afruehstueck.github.io/vive3D/'},
            { 'arxiv': 'https://arxiv.org/abs/2303.15469',
              'conf': 'CVPR 2023',
              'github': 'https://github.com/cams-hoi/CAMS',
              'title': 'CAMS: CAnonicalized Manipulation Spaces for '
                       'Category-Level Functional Hand-Object Manipulation '
                       'Synthesis',
              'website': 'https://cams-hoi.github.io/'},
            { 'arxiv': 'https://arxiv.org/abs/2303.14109',
              'conf': None,
              'github': None,
              'title': 'Prediction of the morphological evolution of a '
                       'splashing drop using an encoder-decoder',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2303.13497',
              'conf': None,
              'github': None,
              'title': 'TriPlaneNet: An Encoder for EG3D Inversion',
              'website': 'https://anantarb.github.io/triplanenet'},
            { 'arxiv': 'https://arxiv.org/abs/2303.09857',
              'conf': 'CVPR 2023',
              'github': 'https://github.com/park-jungin/DualPath',
              'title': 'Dual-path Adaptation from Image to Video Transformers',
              'website': None},
            { 'arxiv': 'https://arxiv.org/abs/2303.04761',
              'conf': None,
              'github': 'https://github.com/ShaoTengLiu/Video-P2P',
              'title': 'Video-P2P: Video Editing with Cross-attention Control',
              'website': 'https://video-p2p.github.io/'},
            { 'arxiv': 'https://arxiv.org/abs/2302.14683',
              'conf': None,
              'github': None,
              'title': 'IntrinsicNGP: Intrinsic Coordinate based Hash Encoding '
                       'for Human NeRF',
              'website': 'https://ustc3dv.github.io/IntrinsicNGP/'},
            { 'arxiv': 'https://arxiv.org/abs/2301.02239',
              'conf': 'CVPR 2023',
              'github': 'https://github.com/facebookresearch/robust-dynrf',
              'title': 'Robust Dynamic Radiance Fields',
              'website': 'https://robust-dynrf.github.io/'}]}
